{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "EK8cwgHbfK4I"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import os\n",
    "import re # regex to extract hrefs and names\n",
    "from urllib.parse import urljoin # for joining url segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0-e8PTqifK4N"
   },
   "outputs": [],
   "source": [
    "core_url = \"https://www.mgmt.ucl.ac.uk\"\n",
    "response = requests.get(urljoin(core_url, '/study'))\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GRBtivPCfK4O"
   },
   "outputs": [],
   "source": [
    "# get all list items from HTML data within the 'menu nav' class unordered list\n",
    "study_pages = soup.find('ul', class_='menu nav').find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pk5WRuEAfK4P"
   },
   "outputs": [],
   "source": [
    "# convert to string\n",
    "study_pages = [str(page) for page in study_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hW11iS1nfK4P"
   },
   "outputs": [],
   "source": [
    "# list of potential degree types\n",
    "degree_types = ['BSc', 'MSc', 'MRes', 'MBA', 'PhD']\n",
    "\n",
    "# filter pages to only those that are about a degree\n",
    "degree_pages = [page for page in study_pages if any(word in page for word in degree_types)]\n",
    "\n",
    "# extract and map url endings for each degree\n",
    "degree_pages_url = {\n",
    "    re.search(r'href=\"/\\b[a-zA-Z-]+', page).group().replace('href=\"', '') : # retrieves href\n",
    "    re.search(r'\">[A-Za-z/ ]+', page).group().replace('\">', '') # retrieves programme name\n",
    "    for page in degree_pages\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PxXUPNsOfK4Q",
    "outputId": "35499a7b-5d01-4cc8-e021-b8592ea2db4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/imb', '/management-science', '/business-analytics', '/entrepreneurship', '/finance', '/management', '/ucl-mba', '/mba-peking-university', '/phd-financial-economics', '/phd']\n",
      "['BSc Information Management For Business', 'BSc/MSci Management Science', 'MSc Business Analytics', 'MSc Entrepreneurship', 'MSc Finance', 'MSc Management', 'The UCL MBA', 'The UCL MBA with Peking University', 'MRes and PhD in Financial Economics', 'MRes and PhD in Management']\n"
     ]
    }
   ],
   "source": [
    "# keys (url ending)\n",
    "print(list(degree_pages_url.keys()))\n",
    "\n",
    "# values (page name)\n",
    "print(list(degree_pages_url.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('test/within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each degree corpus, degree paragraph, in separate files\n",
    "for url_ending in degree_pages_url:\n",
    "    # fetch HTML\n",
    "    url = urljoin(core_url, url_ending)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tags = soup.find('div', class_='field-item even') # this div contains the degree text content\n",
    "\n",
    "    # create the file name, replacing any illegal / characters with - \n",
    "    file_name = os.path.join('corpus', degree_pages_url[url_ending].replace('/', '-') + ' corpus' + '.txt')\n",
    "    \n",
    "    # extract paragraphs from website HTML\n",
    "    paragraphs = [tag.get_text(separator = ' ').replace('\\xa0', ' ') for tag in tags.select('p,ul,div.msi-faq-answer') if tag.get_text() not in ['\\xa0', '', '\\n']]\n",
    "    # remove tab characters\n",
    "    paragraphs = [re.sub('\\t', '', para) for para in paragraphs]\n",
    "    # remove spaces at start of lines\n",
    "    paragraphs = [re.sub('\\n ', '\\n', para) for para in paragraphs]\n",
    "    # remove unicode zero width space character\n",
    "    paragraphs = [re.sub('\\u200b', '', para) for para in paragraphs]\n",
    "    # remove extra spaces\n",
    "    paragraphs = [re.sub(' +', ' ', para) for para in paragraphs]\n",
    "    \n",
    "    # save whole corpus\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        scraped_text = '\\n\\n'.join(paragraphs)\n",
    "        f.write(scraped_text) # extract the text from html and write to file\n",
    "        \n",
    "    # save each individual paragraph (\"context\") as a separate file\n",
    "    counter = 1\n",
    "    # make folder to store contexts\n",
    "    context_folder = os.path.join('corpus', url_ending.replace('/', ''))\n",
    "    # only make subfolder if it doesn't exist\n",
    "    if not os.path.exists(context_folder):\n",
    "        os.mkdir(context_folder)\n",
    "    \n",
    "    # save each paragraph as separate file\n",
    "    for para in paragraphs:\n",
    "        # name paragraph as n.txt\n",
    "        context_file_name = str(counter) + '.txt'\n",
    "        with open(os.path.join(context_folder, context_file_name), 'w', encoding='utf-8') as f:\n",
    "            f.write(para)\n",
    "        counter+=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "som-scraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
