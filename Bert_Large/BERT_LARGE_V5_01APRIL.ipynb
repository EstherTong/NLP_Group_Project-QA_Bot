{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENdpke4xAOWx"
   },
   "source": [
    "https://towardsdatascience.com/question-answering-with-a-fine-tuned-bert-bc4dafd45626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2QqmS9aiowP",
    "outputId": "209bb839-74ec-4eef-f91a-b28bb54efee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.8.1 tokenizers-0.12.1 transformers-4.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S4wWBUQsjLm0"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/neuml/txtai datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.1\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.07.19 |       h06a4308_0         124 KB\n",
      "    certifi-2022.6.15          |   py38h06a4308_0         153 KB\n",
      "    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB\n",
      "    ffmpeg-4.3                 |       hf484d3e_0         9.9 MB  pytorch\n",
      "    gnutls-3.6.15              |       he1e5248_0         1.0 MB\n",
      "    lame-3.100                 |       h7b6447c_0         323 KB\n",
      "    libiconv-1.16              |       h7f8727e_2         736 KB\n",
      "    libidn2-2.3.2              |       h7f8727e_0          81 KB\n",
      "    libtasn1-4.16.0            |       h27cfd23_0          58 KB\n",
      "    libunistring-0.9.10        |       h27cfd23_0         536 KB\n",
      "    nettle-3.7.3               |       hbbd107a_1         809 KB\n",
      "    openh264-2.1.1             |       h4ff587b_0         711 KB\n",
      "    openssl-1.1.1q             |       h7f8727e_0         2.5 MB\n",
      "    pytorch-1.12.1             |py3.8_cuda10.2_cudnn7.6.5_0       624.7 MB  pytorch\n",
      "    pytorch-mutex-1.0          |             cuda           3 KB  pytorch\n",
      "    torchvision-0.13.1         |       py38_cu102        24.6 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        1.01 GB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1\n",
      "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0\n",
      "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0\n",
      "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0\n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.16-h7f8727e_2\n",
      "  libidn2            pkgs/main/linux-64::libidn2-2.3.2-h7f8727e_0\n",
      "  libtasn1           pkgs/main/linux-64::libtasn1-4.16.0-h27cfd23_0\n",
      "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0\n",
      "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1\n",
      "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0\n",
      "  pytorch            pytorch/linux-64::pytorch-1.12.1-py3.8_cuda10.2_cudnn7.6.5_0\n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda\n",
      "  torchvision        pytorch/linux-64::torchvision-0.13.1-py38_cu102\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2021.5.25-h06a4308_1 --> 2022.07.19-h06a4308_0\n",
      "  certifi                          2021.5.30-py38h06a4308_0 --> 2022.6.15-py38h06a4308_0\n",
      "  openssl                                 1.1.1k-h27cfd23_0 --> 1.1.1q-h7f8727e_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "torchvision-0.13.1   | 24.6 MB   | ##################################### | 100% \n",
      "gnutls-3.6.15        | 1.0 MB    | ##################################### | 100% \n",
      "libtasn1-4.16.0      | 58 KB     | ##################################### | 100% \n",
      "ca-certificates-2022 | 124 KB    | ##################################### | 100% \n",
      "cudatoolkit-10.2.89  | 365.1 MB  | ##################################### | 100% \n",
      "nettle-3.7.3         | 809 KB    | ##################################### | 100% \n",
      "pytorch-1.12.1       | 624.7 MB  | ##################################### | 100% \n",
      "libidn2-2.3.2        | 81 KB     | ##################################### | 100% \n",
      "openssl-1.1.1q       | 2.5 MB    | ##################################### | 100% \n",
      "ffmpeg-4.3           | 9.9 MB    | ##################################### | 100% \n",
      "libiconv-1.16        | 736 KB    | ##################################### | 100% \n",
      "pytorch-mutex-1.0    | 3 KB      | ##################################### | 100% \n",
      "libunistring-0.9.10  | 536 KB    | ##################################### | 100% \n",
      "lame-3.100           | 323 KB    | ##################################### | 100% \n",
      "openh264-2.1.1       | 711 KB    | ##################################### | 100% \n",
      "certifi-2022.6.15    | 153 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch torchvision -c pytorch --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lFhYQidz1ykK"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-680bd6d913e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertForQuestionAnswering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "RLJt3dBM1_vL"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/project/question-answers-processed/fin-ba-processed-combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_dev = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1633 entries, 1849 to 1126\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    1633 non-null   int64  \n",
      " 1   question      1633 non-null   object \n",
      " 2   answers       1633 non-null   object \n",
      " 3   context_file  1633 non-null   object \n",
      " 4   answer_start  1633 non-null   float64\n",
      " 5   answer_end    1633 non-null   float64\n",
      " 6   context       1633 non-null   object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_dev into a validation and test set\n",
    "df_dev, df_test = df_dev[:205], df_dev[205:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8_5vViejA5b",
    "outputId": "ee6f1c33-95be-4a0d-fdbb-f7fee944aea6"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "x=0\n",
    "data_train=[]\n",
    "while x < 1633:\n",
    "  dataset = {\"context\": df_train['context'].iloc[x], \"question\": df_train['question'].iloc[x], \"answers\": df_train['answers'].iloc[x]}\n",
    "           \n",
    "  data_train.append(dataset)\n",
    "  x+=1\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from txtai.pipeline import HFTrainer\n",
    "trainer = HFTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4100' max='4100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4100/4100 02:47, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.244100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.142600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_baseline, tokenizer_baseline = trainer(\"mbartolo/electra-large-synqa\", data_train, task=\"question-answering\", num_train_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "questions_baseline = pipeline(\"question-answering\", model=model_baseline, tokenizer=tokenizer_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003400693240109831"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_baseline(df_dev.loc[1]['question'], df_dev.loc[1]['context'])['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_baseline = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = questions_baseline(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_baseline = pd.concat([result_baseline, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_baseline['comparison'] = np.where(result_baseline['answer'] == result_baseline['model_answer'] , 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_baseline.to_csv('./result_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    124\n",
       "True      81\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_baseline.comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# get tokens from text; just by splitting by spces\n",
    "def get_simple_tokens(text):\n",
    "    tokens = [token.strip() for token in text.split()]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# calculate f1 score for a single prediction-answer pair\n",
    "def get_f1(pred, answer):\n",
    "    pred_tokens = get_simple_tokens(pred)\n",
    "    ans_tokens = get_simple_tokens(answer)\n",
    "    \n",
    "    common_tokens = collections.Counter(pred_tokens) & collections.Counter(ans_tokens)\n",
    "    common_tokens_n = sum(common_tokens.values())\n",
    "    \n",
    "    if common_tokens_n == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = 1.0 * common_tokens_n/len(pred_tokens)\n",
    "    recall = 1.0 * common_tokens_n/len(ans_tokens)\n",
    "    \n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all answers, for df use for i in range(result_df.shape[0])\n",
    "\n",
    "f1_scores = []\n",
    "for i in range(result_baseline.shape[0]):\n",
    "    f1_scores.append(get_f1(result_baseline['model_answer'].values[i], result_baseline['answer'].values[i]))\n",
    "    \n",
    "result_baseline['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47476446037078057"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_baseline['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_baseline.save_pretrained('./bert_large_model_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from transformers import AutoModel\n",
    "#model = AutoModel.from_pretrained('./bert_large_model_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Fine tune with Bert miniture google/bert_uncased_L-2_H-128_A-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283,
     "referenced_widgets": [
      "4d524797f3144f9c978397e61b023c76",
      "44f0a4cec91547a4a9e76b27ae8ee7ed",
      "02cef3b14e6c41c4b3814651815580d4",
      "6200ec02fb814cabb6304f9103c29d34",
      "9f48b29636a041db99769752f9418616",
      "a5925c1f124f40e2a72e793c7623e051",
      "4f278c2f519142c08bbee2a3be8dca03",
      "1fca241ffc384ce69aa072702a3fd795",
      "d27fea3aca9c4c2a81a94f3ac8eb2b96",
      "b43e82517b8c45f481369733683126d5",
      "b22d927057384f01bd84f27dca536928"
     ]
    },
    "id": "VMJ-ZS9tjMh9",
    "outputId": "74e9b893-2506-4802-c8bc-23aed859f11c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 21:57:40,846 [WARNING] download_and_prepare: Reusing dataset squad_v2 (/home/faculty/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b88bd9f4a244c3922785e8ccc8f039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 21:57:44,285 [WARNING] _map_single: Loading cached processed dataset at /home/faculty/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-6659ecdda78b635a.arrow\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3756' max='3756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3756/3756 04:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.333700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.668200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.981600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from txtai.pipeline import HFTrainer\n",
    "\n",
    "ds = load_dataset(\"squad_v2\")\n",
    "\n",
    "trainer_fine_tune1 = HFTrainer()\n",
    "trainer_fine_tune1(\"google/bert_uncased_L-2_H-128_A-2\", ds[\"train\"].select(range(10000)), task=\"question-answering\", output_dir=\"google/electra-large-discriminator\")\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "AoiPsMC6gWEV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4100' max='4100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4100/4100 02:48, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.244100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.142600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_finetune1, tokenizer_finetune1 = trainer_fine_tune1(\"google/electra-large-discriminator\", df_train, task=\"question-answering\", num_train_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "questions_finetune1 = pipeline(\"question-answering\", model=model_finetune1, tokenizer=tokenizer_finetune1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune1 = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = questions_finetune1(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_finetune1 = pd.concat([result_finetune1, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune1['comparison'] = np.where(result_finetune1['answer'] == result_finetune1['model_answer'] , 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>.</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>644</td>\n",
       "      <td>645</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>0.998889</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>You</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For the master program in Finance, what suppor...</td>\n",
       "      <td>please visit UCL's prospective students Corona...</td>\n",
       "      <td>pages</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>388</td>\n",
       "      <td>393</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Is ba master offerred as a part-time study?</td>\n",
       "      <td>No, unfortunately this programme is not offere...</td>\n",
       "      <td>No, unfortunately this programme is not offere...</td>\n",
       "      <td>0.999099</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>For MSc Finance, what are the contact details ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can I apply for a part-time analytics master s...</td>\n",
       "      <td>No, unfortunately this programme is not offere...</td>\n",
       "      <td>No, unfortunately this programme is not offere...</td>\n",
       "      <td>0.998493</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Who should I contact for further details regar...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I have concerns about studying for the Finance...</td>\n",
       "      <td>please visit UCL's prospective students Corona...</td>\n",
       "      <td>pages</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>388</td>\n",
       "      <td>393</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How much is the tuition fee for international ...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>0.992519</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Is there any classes that are held in main Blo...</td>\n",
       "      <td>Canary Wharf</td>\n",
       "      <td>Canary Wharf</td>\n",
       "      <td>0.998993</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>For the master program in Finance, how can I f...</td>\n",
       "      <td>Take a look at the UCL fees and funding pages ...</td>\n",
       "      <td>Take a look at the UCL fees and funding pages ...</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>71</td>\n",
       "      <td>129</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>When will the BA program start for 2023/24 aca...</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>0.292327</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>When is the start date for applying the Financ...</td>\n",
       "      <td>18 October 2021</td>\n",
       "      <td>18 October 2021</td>\n",
       "      <td>0.996670</td>\n",
       "      <td>51</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>For the Finance master, are relevant work expe...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What are the main programming language that BA...</td>\n",
       "      <td>The core elements of the programme are deliver...</td>\n",
       "      <td>.</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What is the minimum requirement for English la...</td>\n",
       "      <td>Applicants whose first language is not English...</td>\n",
       "      <td>a minimum of 6.5 in each of the subtests.</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>349</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the tuition fee for local students for...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>0.980764</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>When will the MSc Business Analytics program s...</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>0.211197</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Who can I contact for further details regardin...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>When is the deadline for applying for MSc Busi...</td>\n",
       "      <td>31 March 2022</td>\n",
       "      <td>31 March 2022</td>\n",
       "      <td>0.662126</td>\n",
       "      <td>122</td>\n",
       "      <td>135</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Do I need to submit a Resume or CV for the Fin...</td>\n",
       "      <td>We also require a copy of your CV.</td>\n",
       "      <td>We also require a copy of your CV.</td>\n",
       "      <td>0.998512</td>\n",
       "      <td>382</td>\n",
       "      <td>416</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>For the master program in Finance, where does ...</td>\n",
       "      <td>Canary Wharf</td>\n",
       "      <td>Canary Wharf</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>251</td>\n",
       "      <td>263</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   Do I need basic finance knowledge for the Fina...   \n",
       "1   For MSc Finance, what is the structure of the ...   \n",
       "2   What is the requirement for GMAR or GRE exam f...   \n",
       "3   For the master program in Finance, who should ...   \n",
       "4   What information do I need to provide for my M...   \n",
       "5   For the master program in Finance, what suppor...   \n",
       "6         Is ba master offerred as a part-time study?   \n",
       "7   For MSc Finance, what are the contact details ...   \n",
       "8   Can I apply for a part-time analytics master s...   \n",
       "9   Who should I contact for further details regar...   \n",
       "10  I have concerns about studying for the Finance...   \n",
       "11  How much is the tuition fee for international ...   \n",
       "12  Is there any classes that are held in main Blo...   \n",
       "13  For the master program in Finance, how can I f...   \n",
       "14  When will the BA program start for 2023/24 aca...   \n",
       "15  When is the start date for applying the Financ...   \n",
       "16  For the Finance master, are relevant work expe...   \n",
       "17  What are the main programming language that BA...   \n",
       "18  What is the minimum requirement for English la...   \n",
       "19  What is the tuition fee for local students for...   \n",
       "20  When will the MSc Business Analytics program s...   \n",
       "21  Who can I contact for further details regardin...   \n",
       "22  When is the deadline for applying for MSc Busi...   \n",
       "23  Do I need to submit a Resume or CV for the Fin...   \n",
       "24  For the master program in Finance, where does ...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   MSc Finance students are expected to have basi...   \n",
       "1   All participants study four core modules in Te...   \n",
       "2                   We do not require GMAT/GRE scores   \n",
       "3   the Programme Administrator via email at: mgmt...   \n",
       "4   You will need to include a degree transcript i...   \n",
       "5   please visit UCL's prospective students Corona...   \n",
       "6   No, unfortunately this programme is not offere...   \n",
       "7   the Programme Administrator via email at: mgmt...   \n",
       "8   No, unfortunately this programme is not offere...   \n",
       "9   the Programme Administrator via email at: mgmt...   \n",
       "10  please visit UCL's prospective students Corona...   \n",
       "11                           UK/EU/Overseas - £38,000   \n",
       "12                                       Canary Wharf   \n",
       "13  Take a look at the UCL fees and funding pages ...   \n",
       "14                                     September 2022   \n",
       "15                                    18 October 2021   \n",
       "16  MSc Finance students are expected to have basi...   \n",
       "17  The core elements of the programme are deliver...   \n",
       "18  Applicants whose first language is not English...   \n",
       "19                           UK/EU/Overseas - £38,000   \n",
       "20                                     September 2022   \n",
       "21  the Programme Administrator via email at: mgmt...   \n",
       "22                                      31 March 2022   \n",
       "23                 We also require a copy of your CV.   \n",
       "24                                       Canary Wharf   \n",
       "\n",
       "                                         model_answer  confidence_score  \\\n",
       "0                                                 MSc          0.000334   \n",
       "1                                                   .          0.000340   \n",
       "2                   We do not require GMAT/GRE scores          0.998889   \n",
       "3                                                 the          0.000716   \n",
       "4                                                 You          0.000285   \n",
       "5                                               pages          0.000326   \n",
       "6   No, unfortunately this programme is not offere...          0.999099   \n",
       "7                                                 the          0.001144   \n",
       "8   No, unfortunately this programme is not offere...          0.998493   \n",
       "9                                                 the          0.000709   \n",
       "10                                              pages          0.000626   \n",
       "11                           UK/EU/Overseas - £38,000          0.992519   \n",
       "12                                       Canary Wharf          0.998993   \n",
       "13  Take a look at the UCL fees and funding pages ...          0.999511   \n",
       "14                                     September 2022          0.292327   \n",
       "15                                    18 October 2021          0.996670   \n",
       "16                                                MSc          0.000204   \n",
       "17                                                  .          0.000359   \n",
       "18          a minimum of 6.5 in each of the subtests.          0.000045   \n",
       "19                           UK/EU/Overseas - £38,000          0.980764   \n",
       "20                                     September 2022          0.211197   \n",
       "21                                                the          0.000759   \n",
       "22                                      31 March 2022          0.662126   \n",
       "23                 We also require a copy of your CV.          0.998512   \n",
       "24                                       Canary Wharf          0.996075   \n",
       "\n",
       "   start_index end_index comparison  \n",
       "0            0         3      False  \n",
       "1          644       645      False  \n",
       "2          378       411       True  \n",
       "3           76        79      False  \n",
       "4            0         3      False  \n",
       "5          388       393      False  \n",
       "6            0        69       True  \n",
       "7           76        79      False  \n",
       "8            0        69       True  \n",
       "9           76        79      False  \n",
       "10         388       393      False  \n",
       "11          63        87       True  \n",
       "12          80        92       True  \n",
       "13          71       129       True  \n",
       "14          38        52       True  \n",
       "15          51        66       True  \n",
       "16           0         3      False  \n",
       "17         150       151      False  \n",
       "18         349       390      False  \n",
       "19          63        87       True  \n",
       "20          38        52       True  \n",
       "21          76        79      False  \n",
       "22         122       135       True  \n",
       "23         382       416       True  \n",
       "24         251       263       True  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finetune1.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune1.to_csv('./result_finetune1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    124\n",
       "True      81\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finetune1.comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "for i in range(result_finetune1.shape[0]):\n",
    "    f1_scores.append(get_f1(result_finetune1['model_answer'].values[i], result_finetune1['answer'].values[i]))\n",
    "    \n",
    "result_finetune1['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47476446037078057"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finetune1['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_finetune1.save_pretrained('Project/test/Esther/bert_large_model_finetune1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Fine tune with google/bert_uncased_L-4_H-512_A-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 23:29:15,981 [WARNING] download_and_prepare: Reusing dataset squad_v2 (/home/faculty/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b56dcdf850545a6bf298d99d6e2d74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 23:29:19,344 [WARNING] _map_single: Loading cached processed dataset at /home/faculty/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-541f82dd7c186b64.arrow\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at google/bert_uncased_L-4_H-512_A-8 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda/envs/Python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3756' max='3756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3756/3756 54:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.778900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.083500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.859500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.855500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "#from txtai.pipeline import HFTrainer\n",
    "\n",
    "ds = load_dataset(\"squad_v2\")\n",
    "\n",
    "trainer_finetune2 = HFTrainer()\n",
    "trainer_finetune2(\"google/bert_uncased_L-4_H-512_A-8\", ds[\"train\"].select(range(10000)), task=\"question-answering\", output_dir=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4100' max='4100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4100/4100 27:33, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.275700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_finetune2, tokenizer_finetune2 = trainer_finetune2(\"bert-large-uncased-whole-word-masking-finetuned-squad\", df_train, task=\"question-answering\", num_train_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_finetune2 = pipeline(\"question-answering\", model=model_finetune2, tokenizer=tokenizer_finetune2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune2 = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = questions_finetune2(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'context': df_dev['context'].values[i], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_finetune2 = pd.concat([result_finetune2, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune2['comparison'] = np.where(result_finetune2['answer'] == result_finetune2['model_answer'] , 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    122\n",
       "True      83\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finetune2.comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "for i in range(result_finetune2.shape[0]):\n",
    "    f1_scores.append(get_f1(result_finetune2['model_answer'].values[i], result_finetune2['answer'].values[i]))\n",
    "    \n",
    "result_finetune2['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46584836340025"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finetune2['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune2.to_csv('./result_finetune2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_finetune2.save_pretrained('Project/test/Esther/bert_large_model_finetune2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third fine tune with google/bert_uncased_L-8_H-512_A-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 01:34:39,484 [WARNING] download_and_prepare: Reusing dataset squad_v2 (/home/faculty/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664dd506fbeb4a13815c6e78898a2336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 01:34:42,840 [WARNING] _map_single: Loading cached processed dataset at /home/faculty/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-6d2378291ddc6d3b.arrow\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-512_A-8 were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at google/bert_uncased_L-8_H-512_A-8 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda/envs/Python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3756' max='3756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3756/3756 1:42:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.486400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.995400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.990600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.603300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "#from txtai.pipeline import HFTrainer\n",
    "\n",
    "ds = load_dataset(\"squad_v2\")\n",
    "\n",
    "trainer_finetune3 = HFTrainer()\n",
    "trainer_finetune3(\"google/bert_uncased_L-8_H-512_A-8\", ds[\"train\"].select(range(10000)), task=\"question-answering\", output_dir=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4100' max='4100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4100/4100 49:59, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.248800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_finetune3, tokenizer_finetune3 = trainer_finetune3(\"bert-large-uncased-whole-word-masking-finetuned-squad\", df_train, task=\"question-answering\", num_train_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "questions_finetune3 = pipeline(\"question-answering\", model=model_finetune3, tokenizer=tokenizer_finetune3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune3 = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = questions_finetune3(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_finetune3 = pd.concat([result_finetune3, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune3['comparison'] = np.where(result_finetune3['answer'] == result_finetune3['model_answer'] , 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    122\n",
       "True      83\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finetune3.comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>2.063777e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>module</td>\n",
       "      <td>4.307857e-06</td>\n",
       "      <td>638</td>\n",
       "      <td>644</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>9.999952e-01</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>the</td>\n",
       "      <td>4.052202e-06</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>.</td>\n",
       "      <td>7.471557e-06</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>the</td>\n",
       "      <td>4.495369e-06</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>.</td>\n",
       "      <td>7.933648e-07</td>\n",
       "      <td>226</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>All</td>\n",
       "      <td>4.302269e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>9.999933e-01</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>9.999933e-01</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Do I need basic finance knowledge for the Fina...   \n",
       "1    For MSc Finance, what is the structure of the ...   \n",
       "2    What is the requirement for GMAR or GRE exam f...   \n",
       "3    For the master program in Finance, who should ...   \n",
       "4    What information do I need to provide for my M...   \n",
       "..                                                 ...   \n",
       "200  Is there a contact email for potential candita...   \n",
       "201  Does my bachelor degree has to be highly numer...   \n",
       "202  What is the structure of the program for the m...   \n",
       "203  For the master program in Finance, what is the...   \n",
       "204  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                          model_answer  confidence_score start_index  \\\n",
       "0                                  MSc      2.063777e-06           0   \n",
       "1                               module      4.307857e-06         638   \n",
       "2    We do not require GMAT/GRE scores      9.999952e-01         378   \n",
       "3                                  the      4.052202e-06          76   \n",
       "4                                    .      7.471557e-06         231   \n",
       "..                                 ...               ...         ...   \n",
       "200                                the      4.495369e-06          76   \n",
       "201                                  .      7.933648e-07         226   \n",
       "202                                All      4.302269e-06           0   \n",
       "203           UK/EU/Overseas - £38,000      9.999933e-01          63   \n",
       "204  We do not require GMAT/GRE scores      9.999933e-01         378   \n",
       "\n",
       "    end_index comparison  \n",
       "0           3      False  \n",
       "1         644      False  \n",
       "2         411       True  \n",
       "3          79      False  \n",
       "4         232      False  \n",
       "..        ...        ...  \n",
       "200        79      False  \n",
       "201       227      False  \n",
       "202         3      False  \n",
       "203        87       True  \n",
       "204       411       True  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finetune3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune3.to_csv('./result_finetune3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "for i in range(result_finetune3.shape[0]):\n",
    "    f1_scores.append(get_f1(result_finetune3['model_answer'].values[i], result_finetune3['answer'].values[i]))\n",
    "    \n",
    "result_finetune3['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46628546162972856"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_finetune3['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_finetune3.save_pretrained('Project/test/Esther/bert_large_model_finetune3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_finetune3 = model_finetune3.from_pretrained('Project/test/Esther/bert_large_model_finetune3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forth fine tune with google/bert_uncased_L-12_H-768_A-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 04:07:40,048 [WARNING] download_and_prepare: Reusing dataset squad_v2 (/home/faculty/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ea30c1cd624e1cbe6a00fd162a9a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 04:07:43,440 [WARNING] _map_single: Loading cached processed dataset at /home/faculty/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-cad1646b6709c846.arrow\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-12_H-768_A-12 were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at google/bert_uncased_L-12_H-768_A-12 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda/envs/Python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3756' max='3756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3756/3756 4:23:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.921700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.718500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.359200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "#from txtai.pipeline import HFTrainer\n",
    "\n",
    "ds = load_dataset(\"squad_v2\")\n",
    "\n",
    "trainer_finetune4 = HFTrainer()\n",
    "trainer_finetune4(\"google/bert_uncased_L-12_H-768_A-12\", ds[\"train\"].select(range(10000)), task=\"question-answering\", output_dir=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1328' max='4100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1328/4100 43:00 < 1:29:54, 0.51 it/s, Epoch 6.47/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.253300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1121b3390b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_finetune3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_finetune4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_finetune4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-large-uncased-whole-word-masking-finetuned-squad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"question-answering\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/txtai/pipeline/train/hftrainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, base, train, validation, columns, maxlength, stride, task, **args)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Run training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Run evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 if (\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_finetune3, tokenizer_finetune4 = trainer_finetune4(\"bert-large-uncased-whole-word-masking-finetuned-squad\", df_train, task=\"question-answering\", num_train_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "questions_finetune4 = pipeline(\"question-answering\", model=model_finetune4, tokenizer=tokenizer_finetune4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune4 = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = questions_finetune4(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_finetune4 = pd.concat([result_finetune4, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune4['comparison'] = np.where(result_finetune4['answer'] == result_finetune4['model_answer'] , 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune4.comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune4.to_csv('./result_finetune4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "for i in range(result_finetune4.shape[0]):\n",
    "    f1_scores.append(get_f1(result_finetune4['model_answer'].values[i], result_finetune4['answer'].values[i]))\n",
    "\n",
    "result_finetune4['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_finetune4['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_finetune4.save_pretrained('Project/test/Esther/bert_large_model_finetune4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_test = pipeline(\"question-answering\", model=model_finetune2, tokenizer=tokenizer_finetune2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_test.shape[0]):\n",
    "    output = questions_test(df_test['question'].values[i], df_test['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_test['question'].values[i], 'answer': df_test['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_test = pd.concat([result_test, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test['comparison'] = np.where(result_test['answer'] == result_test['model_answer'] , 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    137\n",
       "True      67\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test.comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I have to be very quantitative for the mast...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>.</td>\n",
       "      <td>1.145099e-06</td>\n",
       "      <td>226</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, when is the deadline for appl...</td>\n",
       "      <td>31 March 2022</td>\n",
       "      <td>31 March 2022</td>\n",
       "      <td>9.999933e-01</td>\n",
       "      <td>160</td>\n",
       "      <td>173</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For MSc Finance, is experience in the financia...</td>\n",
       "      <td>Experience in the finance and finance-related ...</td>\n",
       "      <td>.</td>\n",
       "      <td>9.821463e-07</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I talk to someone from the faculty to see ...</td>\n",
       "      <td>We consider such requests on a “case by case” ...</td>\n",
       "      <td>We consider such requests on a “case by case” ...</td>\n",
       "      <td>9.999971e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the programming language that I will ...</td>\n",
       "      <td>The core elements of the programme are deliver...</td>\n",
       "      <td>.</td>\n",
       "      <td>2.185180e-06</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For the master program in Finance, do I have t...</td>\n",
       "      <td>prior to 26 September 2022</td>\n",
       "      <td>prior to 26 September 2022</td>\n",
       "      <td>9.999981e-01</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What career path do students of MSc Finance ha...</td>\n",
       "      <td>commercial banks, investment banks, asset mana...</td>\n",
       "      <td>commercial</td>\n",
       "      <td>9.126628e-07</td>\n",
       "      <td>568</td>\n",
       "      <td>578</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many terms am I expected to study for Mast...</td>\n",
       "      <td>The majority of teaching finishes at the end o...</td>\n",
       "      <td>The</td>\n",
       "      <td>1.736272e-06</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>For the master program in Finance, is there an...</td>\n",
       "      <td>Every year over 1,000 employers/organisations ...</td>\n",
       "      <td>Careers</td>\n",
       "      <td>2.858657e-06</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What IELTS score is considered good for the ma...</td>\n",
       "      <td>an overall grade of 7.0 with a minimum of 6.5 ...</td>\n",
       "      <td>.</td>\n",
       "      <td>4.204385e-07</td>\n",
       "      <td>389</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Where does the campus located for MSc Finance?</td>\n",
       "      <td>Canary Wharf</td>\n",
       "      <td>Canary Wharf</td>\n",
       "      <td>9.999905e-01</td>\n",
       "      <td>251</td>\n",
       "      <td>263</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Will the application close before deadline for...</td>\n",
       "      <td>31 March 2022</td>\n",
       "      <td>31 March 2022</td>\n",
       "      <td>9.999962e-01</td>\n",
       "      <td>160</td>\n",
       "      <td>173</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When should I arrive in London for MSc Finance?</td>\n",
       "      <td>prior to 26 September 2022</td>\n",
       "      <td>prior to 26 September 2022</td>\n",
       "      <td>9.999962e-01</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Is there any alternative ways to fund my studi...</td>\n",
       "      <td>Take a look at the UCL fees and funding pages ...</td>\n",
       "      <td>Take a look at the UCL fees and funding pages ...</td>\n",
       "      <td>9.999971e-01</td>\n",
       "      <td>71</td>\n",
       "      <td>129</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Who should I contact for more information rega...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>uk</td>\n",
       "      <td>2.347432e-06</td>\n",
       "      <td>138</td>\n",
       "      <td>140</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>For the master program in Finance, is a Resume...</td>\n",
       "      <td>We also require a copy of your CV.</td>\n",
       "      <td>We also require a copy of your CV.</td>\n",
       "      <td>9.999962e-01</td>\n",
       "      <td>382</td>\n",
       "      <td>416</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>For MSc Finance, who should I contact for more...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>the</td>\n",
       "      <td>2.280966e-06</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Core modules of Business analytics program?</td>\n",
       "      <td>Core modules in Programming for Business Analy...</td>\n",
       "      <td>.</td>\n",
       "      <td>7.126123e-07</td>\n",
       "      <td>233</td>\n",
       "      <td>234</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What kind of programming skills can I expect t...</td>\n",
       "      <td>The core elements of the programme are deliver...</td>\n",
       "      <td>.</td>\n",
       "      <td>1.844192e-06</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the career prospect if I study this Bu...</td>\n",
       "      <td>Graduates from this programme will be highly e...</td>\n",
       "      <td>Graduates</td>\n",
       "      <td>1.295852e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   Do I have to be very quantitative for the mast...   \n",
       "1   For MSc Finance, when is the deadline for appl...   \n",
       "2   For MSc Finance, is experience in the financia...   \n",
       "3   Can I talk to someone from the faculty to see ...   \n",
       "4   What are the programming language that I will ...   \n",
       "5   For the master program in Finance, do I have t...   \n",
       "6   What career path do students of MSc Finance ha...   \n",
       "7   How many terms am I expected to study for Mast...   \n",
       "8   For the master program in Finance, is there an...   \n",
       "9   What IELTS score is considered good for the ma...   \n",
       "10     Where does the campus located for MSc Finance?   \n",
       "11  Will the application close before deadline for...   \n",
       "12    When should I arrive in London for MSc Finance?   \n",
       "13  Is there any alternative ways to fund my studi...   \n",
       "14  Who should I contact for more information rega...   \n",
       "15  For the master program in Finance, is a Resume...   \n",
       "16  For MSc Finance, who should I contact for more...   \n",
       "17        Core modules of Business analytics program?   \n",
       "18  What kind of programming skills can I expect t...   \n",
       "19  What is the career prospect if I study this Bu...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   we stress to our applicants that this programm...   \n",
       "1                                       31 March 2022   \n",
       "2   Experience in the finance and finance-related ...   \n",
       "3   We consider such requests on a “case by case” ...   \n",
       "4   The core elements of the programme are deliver...   \n",
       "5                          prior to 26 September 2022   \n",
       "6   commercial banks, investment banks, asset mana...   \n",
       "7   The majority of teaching finishes at the end o...   \n",
       "8   Every year over 1,000 employers/organisations ...   \n",
       "9   an overall grade of 7.0 with a minimum of 6.5 ...   \n",
       "10                                       Canary Wharf   \n",
       "11                                      31 March 2022   \n",
       "12                         prior to 26 September 2022   \n",
       "13  Take a look at the UCL fees and funding pages ...   \n",
       "14  the Programme Administrator via email at: mgmt...   \n",
       "15                 We also require a copy of your CV.   \n",
       "16  the Programme Administrator via email at: mgmt...   \n",
       "17  Core modules in Programming for Business Analy...   \n",
       "18  The core elements of the programme are deliver...   \n",
       "19  Graduates from this programme will be highly e...   \n",
       "\n",
       "                                         model_answer  confidence_score  \\\n",
       "0                                                   .      1.145099e-06   \n",
       "1                                       31 March 2022      9.999933e-01   \n",
       "2                                                   .      9.821463e-07   \n",
       "3   We consider such requests on a “case by case” ...      9.999971e-01   \n",
       "4                                                   .      2.185180e-06   \n",
       "5                          prior to 26 September 2022      9.999981e-01   \n",
       "6                                          commercial      9.126628e-07   \n",
       "7                                                 The      1.736272e-06   \n",
       "8                                             Careers      2.858657e-06   \n",
       "9                                                   .      4.204385e-07   \n",
       "10                                       Canary Wharf      9.999905e-01   \n",
       "11                                      31 March 2022      9.999962e-01   \n",
       "12                         prior to 26 September 2022      9.999962e-01   \n",
       "13  Take a look at the UCL fees and funding pages ...      9.999971e-01   \n",
       "14                                                 uk      2.347432e-06   \n",
       "15                 We also require a copy of your CV.      9.999962e-01   \n",
       "16                                                the      2.280966e-06   \n",
       "17                                                  .      7.126123e-07   \n",
       "18                                                  .      1.844192e-06   \n",
       "19                                          Graduates      1.295852e-06   \n",
       "\n",
       "   start_index end_index comparison  \n",
       "0          226       227      False  \n",
       "1          160       173       True  \n",
       "2          158       159      False  \n",
       "3            0        52       True  \n",
       "4          150       151      False  \n",
       "5           31        57       True  \n",
       "6          568       578      False  \n",
       "7           80        83      False  \n",
       "8           76        83      False  \n",
       "9          389       390      False  \n",
       "10         251       263       True  \n",
       "11         160       173       True  \n",
       "12          31        57       True  \n",
       "13          71       129       True  \n",
       "14         138       140      False  \n",
       "15         382       416       True  \n",
       "16          76        79      False  \n",
       "17         233       234      False  \n",
       "18         150       151      False  \n",
       "19           0         9      False  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test.to_csv('./result_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "for i in range(result_test.shape[0]):\n",
    "    f1_scores.append(get_f1(result_test['model_answer'].values[i], result_test['answer'].values[i]))\n",
    "    \n",
    "result_test['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3906535150059975"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT LARGE_LATEST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cef3b14e6c41c4b3814651815580d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fca241ffc384ce69aa072702a3fd795",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d27fea3aca9c4c2a81a94f3ac8eb2b96",
      "value": 2
     }
    },
    "1fca241ffc384ce69aa072702a3fd795": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44f0a4cec91547a4a9e76b27ae8ee7ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5925c1f124f40e2a72e793c7623e051",
      "placeholder": "​",
      "style": "IPY_MODEL_4f278c2f519142c08bbee2a3be8dca03",
      "value": "100%"
     }
    },
    "4d524797f3144f9c978397e61b023c76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44f0a4cec91547a4a9e76b27ae8ee7ed",
       "IPY_MODEL_02cef3b14e6c41c4b3814651815580d4",
       "IPY_MODEL_6200ec02fb814cabb6304f9103c29d34"
      ],
      "layout": "IPY_MODEL_9f48b29636a041db99769752f9418616"
     }
    },
    "4f278c2f519142c08bbee2a3be8dca03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6200ec02fb814cabb6304f9103c29d34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b43e82517b8c45f481369733683126d5",
      "placeholder": "​",
      "style": "IPY_MODEL_b22d927057384f01bd84f27dca536928",
      "value": " 2/2 [00:00&lt;00:00, 36.24it/s]"
     }
    },
    "9f48b29636a041db99769752f9418616": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5925c1f124f40e2a72e793c7623e051": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b22d927057384f01bd84f27dca536928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b43e82517b8c45f481369733683126d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d27fea3aca9c4c2a81a94f3ac8eb2b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
