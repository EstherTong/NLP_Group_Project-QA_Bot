{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display the full output in this notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting torch\n",
      "  Using cached torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Using cached tokenizers-0.12.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: click in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.49 tokenizers-0.12.0 transformers-4.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/project/question-answers-processed/fin-ba-processed-combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context_file</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the fee for Business Analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the fee for MSc of Business Analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What's the masters fee for business analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        question  \\\n",
       "0           0         What is the fee for Business Analytics?   \n",
       "1           1  What is the fee for MSc of Business Analytics?   \n",
       "2           2  What's the masters fee for business analytics?   \n",
       "\n",
       "                                answers                     context_file  \\\n",
       "0  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "1  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "2  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "\n",
       "   answer_start  answer_end                                            context  \n",
       "0          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "1          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "2          63.0        99.0  Start date: September 2022 Duration: 12 months...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_dev = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split df_dev into a validation and test set\n",
    "df_dev, df_test = df_dev[:205], df_dev[205:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)\n",
    "len(df_dev)\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_name = 'deepset/bert-base-cased-squad2'\n",
    "\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokenizer(list(df_train[\"context\"]), list(df_train[\"question\"]),\n",
    "                  truncation=True, padding='max_length',\n",
    "                  max_length=512, return_tensors='pt')\n",
    "\n",
    "val = tokenizer(list(df_dev[\"context\"]), list(df_dev[\"question\"]),\n",
    "                  truncation=True, padding='max_length',\n",
    "                  max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # for showing progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] MSc Finance students are expected to have basic knowledge in financial mathematics and econometrics, and should be motivated to take their knowledge to the next level. To get to that next level, we expect a great deal from our students, so if you choose to study with us, you can expect to be working hard, challenging yourself as we challenge you, and regularly finding yourself out of your comfort zone. [SEP] Are relevant work experiences required to be eligible for admission for the master program in Finance? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] MSc Finance students are expected to have basic knowledge in financial mathematics and econometrics, and should be motivated to take their knowledge to the next level. To get to that next level, we expect a great deal from our students, so if you choose to study with us, you can expect to be working hard, challenging yourself as we challenge you, and regularly finding yourself out of your comfort zone. [SEP] Do I need basic finance knowledge for the Finance master? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train['input_ids'][0])\n",
    "tokenizer.decode(val['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.astype({\"answer_start\": int, \"answer_end\": int})\n",
    "df_dev = df_dev.astype({\"answer_start\": int, \"answer_end\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_pos = df_train['answer_start'].tolist()\n",
    "train_end_pos = df_train['answer_end'].tolist()\n",
    "val_start_pos = df_dev['answer_start'].tolist()\n",
    "val_end_pos = df_dev['answer_end'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the start_position & end_position to the dict\n",
    "train.update({'start_positions': train_start_pos, 'end_positions': train_end_pos})\n",
    "val.update({'start_positions': val_start_pos, 'end_positions': val_end_pos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the keys in the dict\n",
    "train.keys()\n",
    "val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using Pytorch\n",
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# build datasets for both our training data\n",
    "train_dataset = SquadDataset(train)\n",
    "val_dataset = SquadDataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed our train dataset\n",
    "\n",
    "batch_size=16\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "#model.train()\n",
    "#criterion = torch.nn.BCELoss()  # binary cross-entropy loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting PyPrind\n",
      "  Using cached PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: PyPrind\n",
      "Successfully installed PyPrind-2.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPrind\n",
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    bar = pyprind.ProgBar(len(train_loader), bar_char='█')\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc\n",
    "        bar.update()\n",
    "    return epoch_loss / len(train_loader)#, epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        bar = pyprind.ProgBar(len(val_loader), bar_char='█')\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            bar.update()\n",
    "    return epoch_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-aca00554063a>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:47\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: nan | Val. Loss: 0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:26\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:07\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Train Loss: 0.565 | Val. Loss: 0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:26\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:08\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Train Loss: 0.279 | Val. Loss: 0.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:05\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Train Loss: 0.194 | Val. Loss: 0.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:08\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Train Loss: nan | Val. Loss: 0.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:23\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Train Loss: 0.102 | Val. Loss: 0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:08\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Train Loss: 0.095 | Val. Loss: 0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:26\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:14\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Train Loss: 0.087 | Val. Loss: 0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:26\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "N_EPOCHS = 8\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    valid_loss = evaluate(model, val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(8):\n",
    "#     loop = tqdm(loader)\n",
    "    \n",
    "    \n",
    "#     for batch in loop:\n",
    "#         optim.zero_grad()\n",
    "\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         start_positions = batch['start_positions'].to(device)\n",
    "#         end_positions = batch['end_positions'].to(device)\n",
    "# #         print('inputid', input_ids)\n",
    "# #         print('inputid', input_ids.shape)\n",
    "# #         print('attnm', attention_mask)\n",
    "# #         print('startpos', start_positions)\n",
    "# #         print('startpos', end_positions)\n",
    "\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, \n",
    "#                         start_positions=start_positions,\n",
    "#                         end_positions=end_positions)\n",
    "        \n",
    "#         loss = outputs[0]\n",
    "#         loss.sum().backward()\n",
    "#         optim.step()\n",
    "\n",
    "#         loop.set_description(f'Epoch {epoch}')\n",
    "#         loop.set_postfix(loss=loss.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the dev model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do I need basic finance knowledge for the Finance master?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['question'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.04625747725367546, 'start': 5, 'end': 9, 'answer': 'good'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "nlp('how are u', 'I am good today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.92779280547984e-06"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(df_dev.loc[1]['question'], df_dev.loc[1]['context'])['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context_file</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1316</td>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>corpus/finance/26.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>corpus/finance/3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1068</td>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>corpus/finance/52.txt</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>Qualifications which are requested to support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969</td>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>corpus/finance/54.txt</td>\n",
       "      <td>76</td>\n",
       "      <td>140</td>\n",
       "      <td>For further information regarding the MSc Fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>529</td>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>corpus/business-analytics/105.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>367</td>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>corpus/business-analytics/73.txt</td>\n",
       "      <td>76</td>\n",
       "      <td>126</td>\n",
       "      <td>For further information regarding the Business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>757</td>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>corpus/finance/28.txt</td>\n",
       "      <td>84</td>\n",
       "      <td>227</td>\n",
       "      <td>While we do welcome students from a wide varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1985</td>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>corpus/finance/3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1582</td>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>corpus/finance/1.txt</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1073</td>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>corpus/finance/52.txt</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>Qualifications which are requested to support ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           question  \\\n",
       "0          1316  Do I need basic finance knowledge for the Fina...   \n",
       "1          1000  For MSc Finance, what is the structure of the ...   \n",
       "2          1068  What is the requirement for GMAR or GRE exam f...   \n",
       "3          1969  For the master program in Finance, who should ...   \n",
       "4           529  What information do I need to provide for my M...   \n",
       "..          ...                                                ...   \n",
       "200         367  Is there a contact email for potential candita...   \n",
       "201         757  Does my bachelor degree has to be highly numer...   \n",
       "202        1985  What is the structure of the program for the m...   \n",
       "203        1582  For the master program in Finance, what is the...   \n",
       "204        1073  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                               answers  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                          context_file  answer_start  answer_end  \\\n",
       "0                corpus/finance/26.txt             0         167   \n",
       "1                 corpus/finance/3.txt             0         644   \n",
       "2                corpus/finance/52.txt           378         411   \n",
       "3                corpus/finance/54.txt            76         140   \n",
       "4    corpus/business-analytics/105.txt             0         232   \n",
       "..                                 ...           ...         ...   \n",
       "200   corpus/business-analytics/73.txt            76         126   \n",
       "201              corpus/finance/28.txt            84         227   \n",
       "202               corpus/finance/3.txt             0         644   \n",
       "203               corpus/finance/1.txt            63          87   \n",
       "204              corpus/finance/52.txt           378         411   \n",
       "\n",
       "                                               context  \n",
       "0    MSc Finance students are expected to have basi...  \n",
       "1    All participants study four core modules in Te...  \n",
       "2    Qualifications which are requested to support ...  \n",
       "3    For further information regarding the MSc Fina...  \n",
       "4    You will need to include a degree transcript i...  \n",
       "..                                                 ...  \n",
       "200  For further information regarding the Business...  \n",
       "201  While we do welcome students from a wide varie...  \n",
       "202  All participants study four core modules in Te...  \n",
       "203  Start date: September 2022 Duration: 12 months...  \n",
       "204  Qualifications which are requested to support ...  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = nlp(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_df = pd.concat([result_df, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dev-set-verification/bert-base-v0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7dc032703cca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev-set-verification/bert-base-v0.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3385\u001b[0m         )\n\u001b[1;32m   3386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3387\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dev-set-verification/bert-base-v0.csv'"
     ]
    }
   ],
   "source": [
    "result_df.to_csv('dev-set-verification/bert-base-v0.csv')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>knowledge to the next level.</td>\n",
       "      <td>6.707409e-07</td>\n",
       "      <td>139</td>\n",
       "      <td>167</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>core modules are studied, again reflecting a q...</td>\n",
       "      <td>8.927793e-06</td>\n",
       "      <td>151</td>\n",
       "      <td>216</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>test provided by UCL to be eligible to receive...</td>\n",
       "      <td>2.944303e-03</td>\n",
       "      <td>590</td>\n",
       "      <td>661</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>the UCL Postgraduate Admissions Website</td>\n",
       "      <td>2.184724e-03</td>\n",
       "      <td>213</td>\n",
       "      <td>252</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>statement</td>\n",
       "      <td>8.683142e-04</td>\n",
       "      <td>113</td>\n",
       "      <td>122</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>admissions please see the UCL Postgraduate Adm...</td>\n",
       "      <td>9.953604e-02</td>\n",
       "      <td>159</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>prepare for.</td>\n",
       "      <td>1.416786e-01</td>\n",
       "      <td>442</td>\n",
       "      <td>454</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>core modules are studied, again reflecting a q...</td>\n",
       "      <td>2.262612e-06</td>\n",
       "      <td>151</td>\n",
       "      <td>216</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>Minimum of 2:1 or</td>\n",
       "      <td>1.119543e-04</td>\n",
       "      <td>254</td>\n",
       "      <td>271</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>test provided by UCL to be eligible to receive...</td>\n",
       "      <td>1.299701e-03</td>\n",
       "      <td>590</td>\n",
       "      <td>661</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Do I need basic finance knowledge for the Fina...   \n",
       "1    For MSc Finance, what is the structure of the ...   \n",
       "2    What is the requirement for GMAR or GRE exam f...   \n",
       "3    For the master program in Finance, who should ...   \n",
       "4    What information do I need to provide for my M...   \n",
       "..                                                 ...   \n",
       "200  Is there a contact email for potential candita...   \n",
       "201  Does my bachelor degree has to be highly numer...   \n",
       "202  What is the structure of the program for the m...   \n",
       "203  For the master program in Finance, what is the...   \n",
       "204  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                                          model_answer  confidence_score  \\\n",
       "0                         knowledge to the next level.      6.707409e-07   \n",
       "1    core modules are studied, again reflecting a q...      8.927793e-06   \n",
       "2    test provided by UCL to be eligible to receive...      2.944303e-03   \n",
       "3              the UCL Postgraduate Admissions Website      2.184724e-03   \n",
       "4                                            statement      8.683142e-04   \n",
       "..                                                 ...               ...   \n",
       "200  admissions please see the UCL Postgraduate Adm...      9.953604e-02   \n",
       "201                                       prepare for.      1.416786e-01   \n",
       "202  core modules are studied, again reflecting a q...      2.262612e-06   \n",
       "203                                  Minimum of 2:1 or      1.119543e-04   \n",
       "204  test provided by UCL to be eligible to receive...      1.299701e-03   \n",
       "\n",
       "    start_index end_index comparison  \n",
       "0           139       167      False  \n",
       "1           151       216      False  \n",
       "2           590       661      False  \n",
       "3           213       252      False  \n",
       "4           113       122      False  \n",
       "..          ...       ...        ...  \n",
       "200         159       220      False  \n",
       "201         442       454      False  \n",
       "202         151       216      False  \n",
       "203         254       271      False  \n",
       "204         590       661      False  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['comparison'] = np.where(result_df['answer'] == result_df['model_answer'] , 'True', 'False')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    200\n",
       "True       5\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# get tokens from text; just by splitting by spces\n",
    "def get_simple_tokens(text):\n",
    "    tokens = [token.strip() for token in text.split()]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# calculate f1 score for a single prediction-answer pair\n",
    "def get_f1(pred, answer):\n",
    "    pred_tokens = get_simple_tokens(pred)\n",
    "    ans_tokens = get_simple_tokens(answer)\n",
    "    \n",
    "    common_tokens = collections.Counter(pred_tokens) & collections.Counter(ans_tokens)\n",
    "    common_tokens_n = sum(common_tokens.values())\n",
    "    \n",
    "    if common_tokens_n == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = 1.0 * common_tokens_n/len(pred_tokens)\n",
    "    recall = 1.0 * common_tokens_n/len(ans_tokens)\n",
    "    \n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all answers, for df use for i in range(result_df.shape[0])\n",
    "\n",
    "f1_scores = []\n",
    "for i in range(result_df.shape[0]):\n",
    "    f1_scores.append(get_f1(result_df['model_answer'].values[i], result_df['answer'].values[i]))\n",
    "    \n",
    "result_df['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2680625774317304"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3643a8640>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3643a8a60>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch #')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Binary Cross-Entropy Loss')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe3643a8cd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "x = list(range(1, 1+len(train_losses)))\n",
    "\n",
    "plt.plot(x, train_losses, 'b', linewidth=2)\n",
    "plt.plot(x, valid_losses, 'r', linewidth=2)\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.legend(('Training Loss', 'Validation Loss'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
