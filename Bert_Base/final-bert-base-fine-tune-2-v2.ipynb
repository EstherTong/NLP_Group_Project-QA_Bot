{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display the full output in this notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting torch\n",
      "  Using cached torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Using cached tokenizers-0.12.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.49 tokenizers-0.12.0 transformers-4.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/project/question-answers-processed/fin-ba-processed-combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context_file</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the fee for Business Analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the fee for MSc of Business Analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What's the masters fee for business analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        question  \\\n",
       "0           0         What is the fee for Business Analytics?   \n",
       "1           1  What is the fee for MSc of Business Analytics?   \n",
       "2           2  What's the masters fee for business analytics?   \n",
       "\n",
       "                                answers                     context_file  \\\n",
       "0  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "1  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "2  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "\n",
       "   answer_start  answer_end                                            context  \n",
       "0          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "1          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "2          63.0        99.0  Start date: September 2022 Duration: 12 months...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_dev = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split df_dev into a validation and test set\n",
    "df_dev, df_test = df_dev[:205], df_dev[205:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)\n",
    "len(df_dev)\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_name = 'deepset/bert-base-cased-squad2'\n",
    "\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokenizer(list(df_train[\"context\"]), list(df_train[\"question\"]),\n",
    "                  truncation=True, padding='max_length',\n",
    "                  max_length=512, return_tensors='pt')\n",
    "\n",
    "val = tokenizer(list(df_dev[\"context\"]), list(df_dev[\"question\"]),\n",
    "                  truncation=True, padding='max_length',\n",
    "                  max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # for showing progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] MSc Finance students are expected to have basic knowledge in financial mathematics and econometrics, and should be motivated to take their knowledge to the next level. To get to that next level, we expect a great deal from our students, so if you choose to study with us, you can expect to be working hard, challenging yourself as we challenge you, and regularly finding yourself out of your comfort zone. [SEP] Are relevant work experiences required to be eligible for admission for the master program in Finance? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] MSc Finance students are expected to have basic knowledge in financial mathematics and econometrics, and should be motivated to take their knowledge to the next level. To get to that next level, we expect a great deal from our students, so if you choose to study with us, you can expect to be working hard, challenging yourself as we challenge you, and regularly finding yourself out of your comfort zone. [SEP] Do I need basic finance knowledge for the Finance master? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train['input_ids'][0])\n",
    "tokenizer.decode(val['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.astype({\"answer_start\": int, \"answer_end\": int})\n",
    "df_dev = df_dev.astype({\"answer_start\": int, \"answer_end\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_pos = df_train['answer_start'].tolist()\n",
    "train_end_pos = df_train['answer_end'].tolist()\n",
    "val_start_pos = df_dev['answer_start'].tolist()\n",
    "val_end_pos = df_dev['answer_end'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the start_position & end_position to the dict\n",
    "train.update({'start_positions': train_start_pos, 'end_positions': train_end_pos})\n",
    "val.update({'start_positions': val_start_pos, 'end_positions': val_end_pos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the keys in the dict\n",
    "train.keys()\n",
    "val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using Pytorch\n",
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# build datasets for both our training data\n",
    "train_dataset = SquadDataset(train)\n",
    "val_dataset = SquadDataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed our train dataset\n",
    "\n",
    "batch_size=16\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "#model.train()\n",
    "#criterion = torch.nn.BCELoss()  # binary cross-entropy loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting PyPrind\n",
      "  Using cached PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: PyPrind\n",
      "Successfully installed PyPrind-2.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPrind\n",
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    bar = pyprind.ProgBar(len(train_loader), bar_char='█')\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc\n",
    "        bar.update()\n",
    "    return epoch_loss / len(train_loader)#, epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        bar = pyprind.ProgBar(len(val_loader), bar_char='█')\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            bar.update()\n",
    "    return epoch_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-aca00554063a>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:07\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 2.743 | Val. Loss: 0.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:20\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Train Loss: nan | Val. Loss: 0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:07\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Train Loss: 0.294 | Val. Loss: 0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:59\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Train Loss: 0.184 | Val. Loss: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "N_EPOCHS = 4\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    valid_loss = evaluate(model, val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(8):\n",
    "#     loop = tqdm(loader)\n",
    "    \n",
    "    \n",
    "#     for batch in loop:\n",
    "#         optim.zero_grad()\n",
    "\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         start_positions = batch['start_positions'].to(device)\n",
    "#         end_positions = batch['end_positions'].to(device)\n",
    "# #         print('inputid', input_ids)\n",
    "# #         print('inputid', input_ids.shape)\n",
    "# #         print('attnm', attention_mask)\n",
    "# #         print('startpos', start_positions)\n",
    "# #         print('startpos', end_positions)\n",
    "\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, \n",
    "#                         start_positions=start_positions,\n",
    "#                         end_positions=end_positions)\n",
    "        \n",
    "#         loss = outputs[0]\n",
    "#         loss.sum().backward()\n",
    "#         optim.step()\n",
    "\n",
    "#         loop.set_description(f'Epoch {epoch}')\n",
    "#         loop.set_postfix(loss=loss.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the dev model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do I need basic finance knowledge for the Finance master?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['question'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.01514357514679432, 'start': 5, 'end': 9, 'answer': 'good'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "nlp('how are u', 'I am good today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2361620349565783e-07"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(df_dev.loc[1]['question'], df_dev.loc[1]['context'])['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context_file</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1316</td>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>corpus/finance/26.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>corpus/finance/3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1068</td>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>corpus/finance/52.txt</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>Qualifications which are requested to support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969</td>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>corpus/finance/54.txt</td>\n",
       "      <td>76</td>\n",
       "      <td>140</td>\n",
       "      <td>For further information regarding the MSc Fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>529</td>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>corpus/business-analytics/105.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>367</td>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>corpus/business-analytics/73.txt</td>\n",
       "      <td>76</td>\n",
       "      <td>126</td>\n",
       "      <td>For further information regarding the Business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>757</td>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>corpus/finance/28.txt</td>\n",
       "      <td>84</td>\n",
       "      <td>227</td>\n",
       "      <td>While we do welcome students from a wide varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1985</td>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>corpus/finance/3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1582</td>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>corpus/finance/1.txt</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1073</td>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>corpus/finance/52.txt</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>Qualifications which are requested to support ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           question  \\\n",
       "0          1316  Do I need basic finance knowledge for the Fina...   \n",
       "1          1000  For MSc Finance, what is the structure of the ...   \n",
       "2          1068  What is the requirement for GMAR or GRE exam f...   \n",
       "3          1969  For the master program in Finance, who should ...   \n",
       "4           529  What information do I need to provide for my M...   \n",
       "..          ...                                                ...   \n",
       "200         367  Is there a contact email for potential candita...   \n",
       "201         757  Does my bachelor degree has to be highly numer...   \n",
       "202        1985  What is the structure of the program for the m...   \n",
       "203        1582  For the master program in Finance, what is the...   \n",
       "204        1073  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                               answers  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                          context_file  answer_start  answer_end  \\\n",
       "0                corpus/finance/26.txt             0         167   \n",
       "1                 corpus/finance/3.txt             0         644   \n",
       "2                corpus/finance/52.txt           378         411   \n",
       "3                corpus/finance/54.txt            76         140   \n",
       "4    corpus/business-analytics/105.txt             0         232   \n",
       "..                                 ...           ...         ...   \n",
       "200   corpus/business-analytics/73.txt            76         126   \n",
       "201              corpus/finance/28.txt            84         227   \n",
       "202               corpus/finance/3.txt             0         644   \n",
       "203               corpus/finance/1.txt            63          87   \n",
       "204              corpus/finance/52.txt           378         411   \n",
       "\n",
       "                                               context  \n",
       "0    MSc Finance students are expected to have basi...  \n",
       "1    All participants study four core modules in Te...  \n",
       "2    Qualifications which are requested to support ...  \n",
       "3    For further information regarding the MSc Fina...  \n",
       "4    You will need to include a degree transcript i...  \n",
       "..                                                 ...  \n",
       "200  For further information regarding the Business...  \n",
       "201  While we do welcome students from a wide varie...  \n",
       "202  All participants study four core modules in Te...  \n",
       "203  Start date: September 2022 Duration: 12 months...  \n",
       "204  Qualifications which are requested to support ...  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = nlp(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_df = pd.concat([result_df, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_test = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_test.shape[0]):\n",
    "    output = nlp(df_test['question'].values[i], df_test['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_test['question'].values[i], 'answer': df_test['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_df = pd.concat([result_df_test, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dev-set-verification/bert-base-v0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7dc032703cca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev-set-verification/bert-base-v0.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3385\u001b[0m         )\n\u001b[1;32m   3386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3387\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dev-set-verification/bert-base-v0.csv'"
     ]
    }
   ],
   "source": [
    "result_df.to_csv('dev-set-verification/bert-base-v0.csv')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>basic knowledge in financial mathematics and e...</td>\n",
       "      <td>3.635168e-05</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>.</td>\n",
       "      <td>1.236162e-07</td>\n",
       "      <td>432</td>\n",
       "      <td>433</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>GMAT/GRE scores -</td>\n",
       "      <td>5.164768e-05</td>\n",
       "      <td>396</td>\n",
       "      <td>413</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>the UCL Postgraduate Admissions Website</td>\n",
       "      <td>1.277545e-03</td>\n",
       "      <td>213</td>\n",
       "      <td>252</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>personal statement</td>\n",
       "      <td>7.101690e-07</td>\n",
       "      <td>104</td>\n",
       "      <td>122</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>mgmt-ba</td>\n",
       "      <td>3.095100e-03</td>\n",
       "      <td>109</td>\n",
       "      <td>116</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>prepare for.</td>\n",
       "      <td>1.421838e-02</td>\n",
       "      <td>442</td>\n",
       "      <td>454</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>.</td>\n",
       "      <td>9.675361e-08</td>\n",
       "      <td>331</td>\n",
       "      <td>332</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>Minimum of 2:1 or equivalent in a relevant dis...</td>\n",
       "      <td>1.365407e-04</td>\n",
       "      <td>254</td>\n",
       "      <td>307</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>GMAT/GRE scores -</td>\n",
       "      <td>3.446659e-04</td>\n",
       "      <td>396</td>\n",
       "      <td>413</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Do I need basic finance knowledge for the Fina...   \n",
       "1    For MSc Finance, what is the structure of the ...   \n",
       "2    What is the requirement for GMAR or GRE exam f...   \n",
       "3    For the master program in Finance, who should ...   \n",
       "4    What information do I need to provide for my M...   \n",
       "..                                                 ...   \n",
       "200  Is there a contact email for potential candita...   \n",
       "201  Does my bachelor degree has to be highly numer...   \n",
       "202  What is the structure of the program for the m...   \n",
       "203  For the master program in Finance, what is the...   \n",
       "204  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                                          model_answer  confidence_score  \\\n",
       "0    basic knowledge in financial mathematics and e...      3.635168e-05   \n",
       "1                                                    .      1.236162e-07   \n",
       "2                                    GMAT/GRE scores -      5.164768e-05   \n",
       "3              the UCL Postgraduate Admissions Website      1.277545e-03   \n",
       "4                                   personal statement      7.101690e-07   \n",
       "..                                                 ...               ...   \n",
       "200                                            mgmt-ba      3.095100e-03   \n",
       "201                                       prepare for.      1.421838e-02   \n",
       "202                                                  .      9.675361e-08   \n",
       "203  Minimum of 2:1 or equivalent in a relevant dis...      1.365407e-04   \n",
       "204                                  GMAT/GRE scores -      3.446659e-04   \n",
       "\n",
       "    start_index end_index comparison  \n",
       "0            42       100      False  \n",
       "1           432       433      False  \n",
       "2           396       413      False  \n",
       "3           213       252      False  \n",
       "4           104       122      False  \n",
       "..          ...       ...        ...  \n",
       "200         109       116      False  \n",
       "201         442       454      False  \n",
       "202         331       332      False  \n",
       "203         254       307      False  \n",
       "204         396       413      False  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['comparison'] = np.where(result_df['answer'] == result_df['model_answer'] , 'True', 'False')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    204\n",
       "True       1\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.comparison.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# get tokens from text; just by splitting by spces\n",
    "def get_simple_tokens(text):\n",
    "    tokens = [token.strip() for token in text.split()]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# calculate f1 score for a single prediction-answer pair\n",
    "def get_f1(pred, answer):\n",
    "    pred_tokens = get_simple_tokens(pred)\n",
    "    ans_tokens = get_simple_tokens(answer)\n",
    "    \n",
    "    common_tokens = collections.Counter(pred_tokens) & collections.Counter(ans_tokens)\n",
    "    common_tokens_n = sum(common_tokens.values())\n",
    "    \n",
    "    if common_tokens_n == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = 1.0 * common_tokens_n/len(pred_tokens)\n",
    "    recall = 1.0 * common_tokens_n/len(ans_tokens)\n",
    "    \n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all answers, for df use for i in range(result_df.shape[0])\n",
    "\n",
    "f1_scores = []\n",
    "for i in range(result_df.shape[0]):\n",
    "    f1_scores.append(get_f1(result_df['model_answer'].values[i], result_df['answer'].values[i]))\n",
    "    \n",
    "result_df['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2303012514052194"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all answers, for df use for i in range(result_df.shape[0])\n",
    "\n",
    "f1_scores_test = []\n",
    "for i in range(result_df_test.shape[0]):\n",
    "    f1_scores_test.append(get_f1(result_df_test['model_answer'].values[i], result_df_test['answer'].values[i]))\n",
    "    \n",
    "result_df_test['f1_score'] = f1_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_test['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc059eba580>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc059eba9a0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch #')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Binary Cross-Entropy Loss')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc059eba760>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "x = list(range(1, 1+len(train_losses)))\n",
    "\n",
    "plt.plot(x, train_losses, 'b', linewidth=2)\n",
    "plt.plot(x, valid_losses, 'r', linewidth=2)\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.legend(('Training Loss', 'Validation Loss'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
