{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting torch\n",
      "  Using cached torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Using cached tokenizers-0.12.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.49 tokenizers-0.12.0 transformers-4.17.0\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting perfplot\n",
      "  Using cached perfplot-0.10.2-py3-none-any.whl (21 kB)\n",
      "Collecting matplotx\n",
      "  Using cached matplotx-0.3.6-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from perfplot) (3.3.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from perfplot) (1.18.5)\n",
      "Collecting rich\n",
      "  Using cached rich-12.0.1-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->perfplot) (1.15.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from rich->perfplot) (2.8.1)\n",
      "Installing collected packages: numpy, commonmark, rich, matplotx, perfplot\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.3.3 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.22.3 which is incompatible.\u001b[0m\n",
      "Successfully installed commonmark-0.9.1 matplotx-0.3.6 numpy-1.22.3 perfplot-0.10.2 rich-12.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install perfplot\n",
    "import ast\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display the full output in this notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context_file</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the fee for Business Analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the fee for MSc of Business Analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What's the masters fee for business analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How much does it cost for international studen...</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How much is it for overseas student to study B...</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0            What is the fee for Business Analytics?   \n",
       "1           1     What is the fee for MSc of Business Analytics?   \n",
       "2           2     What's the masters fee for business analytics?   \n",
       "3           3  How much does it cost for international studen...   \n",
       "4           4  How much is it for overseas student to study B...   \n",
       "\n",
       "                                answers                     context_file  \\\n",
       "0  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "1  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "2  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "3  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "4  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "\n",
       "   answer_start  answer_end                                            context  \n",
       "0          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "1          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "2          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "3          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "4          63.0        99.0  Start date: September 2022 Duration: 12 months...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('/project/question-answers-processed/fin-ba-processed-combined.csv')\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_dev = train_test_split(df_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split df_dev into a validation and test set\n",
    "df_dev, df_test = df_dev[:205], df_dev[205:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)\n",
    "len(df_dev)\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizerFast\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_electra = \"deepset/electra-base-squad2\"\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_electra)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_electra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # for showing progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_trainer = tokenizer(list(df_train[\"context\"]), list(df_train[\"question\"]),\n",
    "                  truncation=True, padding='max_length',\n",
    "                  max_length=512, return_tensors='pt')\n",
    "\n",
    "val_trainer = tokenizer(list(df_dev[\"context\"]), list(df_dev[\"question\"]),\n",
    "                  truncation=True, padding='max_length',\n",
    "                  max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainset\n",
    "len(train_trainer.input_ids[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] msc finance students are expected to have basic knowledge in financial mathematics and econometrics, and should be motivated to take their knowledge to the next level. to get to that next level, we expect a great deal from our students, so if you choose to study with us, you can expect to be working hard, challenging yourself as we challenge you, and regularly finding yourself out of your comfort zone. [SEP] are relevant work experiences required to be eligible for admission for the master program in finance? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_trainer['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] msc finance students are expected to have basic knowledge in financial mathematics and econometrics, and should be motivated to take their knowledge to the next level. to get to that next level, we expect a great deal from our students, so if you choose to study with us, you can expect to be working hard, challenging yourself as we challenge you, and regularly finding yourself out of your comfort zone. [SEP] do i need basic finance knowledge for the finance master? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(val_trainer['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.astype({\"answer_start\": int, \"answer_end\": int})\n",
    "df_dev = df_dev.astype({\"answer_start\": int, \"answer_end\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_pos = df_train['answer_start'].tolist()\n",
    "train_end_pos = df_train['answer_end'].tolist()\n",
    "val_start_pos = df_dev['answer_start'].tolist()\n",
    "val_end_pos = df_dev['answer_end'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the start_position & end_position to the dict\n",
    "train_trainer.update({'start_positions': train_start_pos, 'end_positions': train_end_pos})\n",
    "val_trainer.update({'start_positions': val_start_pos, 'end_positions': val_end_pos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the keys in the dict\n",
    "train_trainer.keys()\n",
    "val_trainer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using Pytorch\n",
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# build datasets for both our training data\n",
    "train_dataset = SquadDataset(train_trainer)\n",
    "val_dataset = SquadDataset(val_trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed our train dataset\n",
    "batch_size=16\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "#model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting PyPrind\n",
      "  Using cached PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: PyPrind\n",
      "Successfully installed PyPrind-2.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPrind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import perfplot\n",
    "\n",
    "# perfplot.show(\n",
    "#     setup=lambda n: torch.randn(n),\n",
    "#     kernels=[\n",
    "#         lambda a: a.new_tensor(a),\n",
    "#         lambda a: a.clone().detach(),\n",
    "#         lambda a: torch.empty_like(a).copy_(a),\n",
    "#         lambda a: torch.tensor(a),\n",
    "#         lambda a: a.detach().clone(),\n",
    "#     ],\n",
    "#     labels=[\"new_tensor()\", \"clone().detach()\", \"empty_like().copy()\", \"tensor()\", \"detach().clone()\"],\n",
    "#     n_range=[2 ** k for k in range(15)],\n",
    "#     xlabel=\"len(a)\",\n",
    "#     logx=False,\n",
    "#     logy=False,\n",
    "#     title='Timing comparison for copying a pytorch tensor',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    bar = pyprind.ProgBar(len(train_loader), bar_char='█')\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc\n",
    "        bar.update()\n",
    "    return epoch_loss / len(train_loader)#, epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        bar = pyprind.ProgBar(len(val_loader), bar_char='█')\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            bar.update()\n",
    "    return epoch_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-c1e7c6d79d72>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:05\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 3.756 | Val. Loss: 1.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:26\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:03\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Train Loss: 1.105 | Val. Loss: 0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:26\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:10\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Train Loss: 0.665 | Val. Loss: 0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:26\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:11\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Train Loss: nan | Val. Loss: 0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:19\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Train Loss: 0.415 | Val. Loss: 0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:14\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Train Loss: 0.417 | Val. Loss: 0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:12\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Train Loss: 0.403 | Val. Loss: 0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:14:10\n",
      "0% [█████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Train Loss: 0.358 | Val. Loss: 0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:27\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "N_EPOCHS = 8\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    valid_loss = evaluate(model, val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(4):\n",
    "#     loop = tqdm(loader)\n",
    "    \n",
    "    \n",
    "#     for batch in loop:\n",
    "#         optim.zero_grad()\n",
    "\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         start_positions = batch['start_positions'].to(device)\n",
    "#         end_positions = batch['end_positions'].to(device)\n",
    "#         #print('inputid', input_ids)\n",
    "#         #print('inputid', input_ids.shape) \n",
    "#         #print('attnm', attention_mask)\n",
    "#         #print('startpos', start_positions)\n",
    "#         #print('startpos', end_positions)\n",
    "\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, \n",
    "#                         start_positions=start_positions,\n",
    "#                         end_positions=end_positions)\n",
    "        \n",
    "#         loss = outputs[0]\n",
    "#         loss.sum().backward()\n",
    "#         optim.step()\n",
    "\n",
    "#         loop.set_description(f'Epoch {epoch}')\n",
    "#         loop.set_postfix(loss=loss.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the dev model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do I need basic finance knowledge for the Finance master?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['question'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0003094155981671065,\n",
       " 'start': 0,\n",
       " 'end': 15,\n",
       " 'answer': 'I am good today'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "nlp('how are u', 'I am good today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005683632334694266"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(df_dev.loc[1]['question'], df_dev.loc[1]['context'])['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context_file</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1316</td>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>corpus/finance/26.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>corpus/finance/3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1068</td>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>corpus/finance/52.txt</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>Qualifications which are requested to support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969</td>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>corpus/finance/54.txt</td>\n",
       "      <td>76</td>\n",
       "      <td>140</td>\n",
       "      <td>For further information regarding the MSc Fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>529</td>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>corpus/business-analytics/105.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>367</td>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>corpus/business-analytics/73.txt</td>\n",
       "      <td>76</td>\n",
       "      <td>126</td>\n",
       "      <td>For further information regarding the Business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>757</td>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>corpus/finance/28.txt</td>\n",
       "      <td>84</td>\n",
       "      <td>227</td>\n",
       "      <td>While we do welcome students from a wide varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1985</td>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>corpus/finance/3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1582</td>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>corpus/finance/1.txt</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1073</td>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>corpus/finance/52.txt</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>Qualifications which are requested to support ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           question  \\\n",
       "0          1316  Do I need basic finance knowledge for the Fina...   \n",
       "1          1000  For MSc Finance, what is the structure of the ...   \n",
       "2          1068  What is the requirement for GMAR or GRE exam f...   \n",
       "3          1969  For the master program in Finance, who should ...   \n",
       "4           529  What information do I need to provide for my M...   \n",
       "..          ...                                                ...   \n",
       "200         367  Is there a contact email for potential candita...   \n",
       "201         757  Does my bachelor degree has to be highly numer...   \n",
       "202        1985  What is the structure of the program for the m...   \n",
       "203        1582  For the master program in Finance, what is the...   \n",
       "204        1073  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                               answers  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                          context_file  answer_start  answer_end  \\\n",
       "0                corpus/finance/26.txt             0         167   \n",
       "1                 corpus/finance/3.txt             0         644   \n",
       "2                corpus/finance/52.txt           378         411   \n",
       "3                corpus/finance/54.txt            76         140   \n",
       "4    corpus/business-analytics/105.txt             0         232   \n",
       "..                                 ...           ...         ...   \n",
       "200   corpus/business-analytics/73.txt            76         126   \n",
       "201              corpus/finance/28.txt            84         227   \n",
       "202               corpus/finance/3.txt             0         644   \n",
       "203               corpus/finance/1.txt            63          87   \n",
       "204              corpus/finance/52.txt           378         411   \n",
       "\n",
       "                                               context  \n",
       "0    MSc Finance students are expected to have basi...  \n",
       "1    All participants study four core modules in Te...  \n",
       "2    Qualifications which are requested to support ...  \n",
       "3    For further information regarding the MSc Fina...  \n",
       "4    You will need to include a degree transcript i...  \n",
       "..                                                 ...  \n",
       "200  For further information regarding the Business...  \n",
       "201  While we do welcome students from a wide varie...  \n",
       "202  All participants study four core modules in Te...  \n",
       "203  Start date: September 2022 Duration: 12 months...  \n",
       "204  Qualifications which are requested to support ...  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = nlp(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_df = pd.concat([result_df, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>students</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>participants study four core modules</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>Qualifications</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>please contact the Programme Administrator</td>\n",
       "      <td>0.021259</td>\n",
       "      <td>61</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>a degree transcript</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>25</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>admissions</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>159</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>prepare</td>\n",
       "      <td>0.057665</td>\n",
       "      <td>442</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>An elective portfolio</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>217</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>:1 or equivalent in a relevant</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>266</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>, such as a 2:1 Bachelor’</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Do I need basic finance knowledge for the Fina...   \n",
       "1    For MSc Finance, what is the structure of the ...   \n",
       "2    What is the requirement for GMAR or GRE exam f...   \n",
       "3    For the master program in Finance, who should ...   \n",
       "4    What information do I need to provide for my M...   \n",
       "..                                                 ...   \n",
       "200  Is there a contact email for potential candita...   \n",
       "201  Does my bachelor degree has to be highly numer...   \n",
       "202  What is the structure of the program for the m...   \n",
       "203  For the master program in Finance, what is the...   \n",
       "204  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                                   model_answer  confidence_score start_index  \\\n",
       "0                                      students          0.000106          12   \n",
       "1          participants study four core modules          0.000568           4   \n",
       "2                                Qualifications          0.003600           0   \n",
       "3    please contact the Programme Administrator          0.021259          61   \n",
       "4                           a degree transcript          0.010026          25   \n",
       "..                                          ...               ...         ...   \n",
       "200                                  admissions          0.000136         159   \n",
       "201                                     prepare          0.057665         442   \n",
       "202                       An elective portfolio          0.001095         217   \n",
       "203              :1 or equivalent in a relevant          0.010552         266   \n",
       "204                   , such as a 2:1 Bachelor’          0.002680          60   \n",
       "\n",
       "    end_index  \n",
       "0          20  \n",
       "1          40  \n",
       "2          14  \n",
       "3         103  \n",
       "4          44  \n",
       "..        ...  \n",
       "200       169  \n",
       "201       449  \n",
       "202       238  \n",
       "203       296  \n",
       "204        85  \n",
       "\n",
       "[205 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.to_csv('dev-set-verification/electra-base-squad2.csv')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>students</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>participants study four core modules</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>Qualifications</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>please contact the Programme Administrator</td>\n",
       "      <td>0.021259</td>\n",
       "      <td>61</td>\n",
       "      <td>103</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>a degree transcript</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>25</td>\n",
       "      <td>44</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>admissions</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>159</td>\n",
       "      <td>169</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>prepare</td>\n",
       "      <td>0.057665</td>\n",
       "      <td>442</td>\n",
       "      <td>449</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>An elective portfolio</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>217</td>\n",
       "      <td>238</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>:1 or equivalent in a relevant</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>266</td>\n",
       "      <td>296</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>, such as a 2:1 Bachelor’</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Do I need basic finance knowledge for the Fina...   \n",
       "1    For MSc Finance, what is the structure of the ...   \n",
       "2    What is the requirement for GMAR or GRE exam f...   \n",
       "3    For the master program in Finance, who should ...   \n",
       "4    What information do I need to provide for my M...   \n",
       "..                                                 ...   \n",
       "200  Is there a contact email for potential candita...   \n",
       "201  Does my bachelor degree has to be highly numer...   \n",
       "202  What is the structure of the program for the m...   \n",
       "203  For the master program in Finance, what is the...   \n",
       "204  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                                   model_answer  confidence_score start_index  \\\n",
       "0                                      students          0.000106          12   \n",
       "1          participants study four core modules          0.000568           4   \n",
       "2                                Qualifications          0.003600           0   \n",
       "3    please contact the Programme Administrator          0.021259          61   \n",
       "4                           a degree transcript          0.010026          25   \n",
       "..                                          ...               ...         ...   \n",
       "200                                  admissions          0.000136         159   \n",
       "201                                     prepare          0.057665         442   \n",
       "202                       An elective portfolio          0.001095         217   \n",
       "203              :1 or equivalent in a relevant          0.010552         266   \n",
       "204                   , such as a 2:1 Bachelor’          0.002680          60   \n",
       "\n",
       "    end_index comparison  \n",
       "0          20      False  \n",
       "1          40      False  \n",
       "2          14      False  \n",
       "3         103      False  \n",
       "4          44      False  \n",
       "..        ...        ...  \n",
       "200       169      False  \n",
       "201       449      False  \n",
       "202       238      False  \n",
       "203       296      False  \n",
       "204        85      False  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['comparison'] = np.where(result_df['answer'] == result_df['model_answer'] , 'True', 'False')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    200\n",
       "True       5\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.comparison.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# get tokens from text; just by splitting by spces\n",
    "def get_simple_tokens(text):\n",
    "    tokens = [token.strip() for token in text.split()]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# calculate f1 score for a single prediction-answer pair\n",
    "def get_f1(pred, answer):\n",
    "    pred_tokens = get_simple_tokens(pred)\n",
    "    ans_tokens = get_simple_tokens(answer)\n",
    "    \n",
    "    common_tokens = collections.Counter(pred_tokens) & collections.Counter(ans_tokens)\n",
    "    common_tokens_n = sum(common_tokens.values())\n",
    "    \n",
    "    if common_tokens_n == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = 1.0 * common_tokens_n/len(pred_tokens)\n",
    "    recall = 1.0 * common_tokens_n/len(ans_tokens)\n",
    "    \n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "for i in range(result_df.shape[0]):\n",
    "    f1_scores.append(get_f1(result_df['model_answer'].values[i], result_df['answer'].values[i]))\n",
    "    \n",
    "result_df['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22281146234028124"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['f1_score'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f969cae7790>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f969cae7be0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch #')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Binary Cross-Entropy Loss')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f969cae7e20>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "x = list(range(1, 1+len(train_losses)))\n",
    "\n",
    "plt.plot(x, train_losses, 'b', linewidth=2)\n",
    "plt.plot(x, valid_losses, 'r', linewidth=2)\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.legend(('Training Loss', 'Validation Loss'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
