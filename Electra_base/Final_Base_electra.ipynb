{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting torch\n",
      "  Using cached torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Using cached tokenizers-0.12.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: click in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.49 tokenizers-0.12.0 transformers-4.17.0\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting perfplot\n",
      "  Using cached perfplot-0.10.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from perfplot) (3.3.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from perfplot) (1.18.5)\n",
      "Collecting matplotx\n",
      "  Using cached matplotx-0.3.6-py3-none-any.whl (24 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-12.0.1-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from matplotlib->perfplot) (8.2.0)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->perfplot) (1.15.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/anaconda/envs/Python3/lib/python3.8/site-packages (from rich->perfplot) (2.8.1)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Installing collected packages: numpy, commonmark, rich, matplotx, perfplot\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.3.3 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.22.3 which is incompatible.\u001b[0m\n",
      "Successfully installed commonmark-0.9.1 matplotx-0.3.6 numpy-1.22.3 perfplot-0.10.2 rich-12.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install perfplot\n",
    "import ast\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display the full output in this notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context_file</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the fee for Business Analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the fee for MSc of Business Analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What's the masters fee for business analytics?</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How much does it cost for international studen...</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How much is it for overseas student to study B...</td>\n",
       "      <td>UK - £19,400, and Overseas - £35,100</td>\n",
       "      <td>corpus/business-analytics/1.txt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0            What is the fee for Business Analytics?   \n",
       "1           1     What is the fee for MSc of Business Analytics?   \n",
       "2           2     What's the masters fee for business analytics?   \n",
       "3           3  How much does it cost for international studen...   \n",
       "4           4  How much is it for overseas student to study B...   \n",
       "\n",
       "                                answers                     context_file  \\\n",
       "0  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "1  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "2  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "3  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "4  UK - £19,400, and Overseas - £35,100  corpus/business-analytics/1.txt   \n",
       "\n",
       "   answer_start  answer_end                                            context  \n",
       "0          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "1          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "2          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "3          63.0        99.0  Start date: September 2022 Duration: 12 months...  \n",
       "4          63.0        99.0  Start date: September 2022 Duration: 12 months...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('/project/question-answers-processed/fin-ba-processed-combined.csv')\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_dev = train_test_split(df_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split df_dev into a validation and test set\n",
    "df_dev, df_test = df_dev[:205], df_dev[205:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)\n",
    "len(df_dev)\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizerFast\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_electra = \"deepset/electra-base-squad2\"\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_electra)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_electra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # for showing progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_trainer = tokenizer(list(df_train[\"context\"]), list(df_train[\"question\"]),\n",
    "                  truncation=True, padding='max_length',\n",
    "                  max_length=512, return_tensors='pt')\n",
    "\n",
    "val_trainer = tokenizer(list(df_dev[\"context\"]), list(df_dev[\"question\"]),\n",
    "                  truncation=True, padding='max_length',\n",
    "                  max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainset\n",
    "len(train_trainer.input_ids[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] msc finance students are expected to have basic knowledge in financial mathematics and econometrics, and should be motivated to take their knowledge to the next level. to get to that next level, we expect a great deal from our students, so if you choose to study with us, you can expect to be working hard, challenging yourself as we challenge you, and regularly finding yourself out of your comfort zone. [SEP] are relevant work experiences required to be eligible for admission for the master program in finance? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_trainer['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] msc finance students are expected to have basic knowledge in financial mathematics and econometrics, and should be motivated to take their knowledge to the next level. to get to that next level, we expect a great deal from our students, so if you choose to study with us, you can expect to be working hard, challenging yourself as we challenge you, and regularly finding yourself out of your comfort zone. [SEP] do i need basic finance knowledge for the finance master? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(val_trainer['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.astype({\"answer_start\": int, \"answer_end\": int})\n",
    "df_dev = df_dev.astype({\"answer_start\": int, \"answer_end\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_pos = df_train['answer_start'].tolist()\n",
    "train_end_pos = df_train['answer_end'].tolist()\n",
    "val_start_pos = df_dev['answer_start'].tolist()\n",
    "val_end_pos = df_dev['answer_end'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the start_position & end_position to the dict\n",
    "train_trainer.update({'start_positions': train_start_pos, 'end_positions': train_end_pos})\n",
    "val_trainer.update({'start_positions': val_start_pos, 'end_positions': val_end_pos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the keys in the dict\n",
    "train_trainer.keys()\n",
    "val_trainer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using Pytorch\n",
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# build datasets for both our training data\n",
    "train_dataset = SquadDataset(train_trainer)\n",
    "val_dataset = SquadDataset(val_trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed our train dataset\n",
    "batch_size=8\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "#model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Collecting PyPrind\n",
      "  Using cached PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: PyPrind\n",
      "Successfully installed PyPrind-2.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPrind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    bar = pyprind.ProgBar(len(train_loader), bar_char='█')\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc\n",
    "        bar.update()\n",
    "    return epoch_loss / len(train_loader)#, epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        bar = pyprind.ProgBar(len(val_loader), bar_char='█')\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            bar.update()\n",
    "    return epoch_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-c1e7c6d79d72>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:15:17\n",
      "0% [██████████████████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 3.018 | Val. Loss: 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:28\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:15:21\n",
      "0% [██████████████████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Train Loss: 0.893 | Val. Loss: 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:28\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:15:10\n",
      "0% [██████████████████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Train Loss: 0.581 | Val. Loss: 0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:28\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:15:09\n",
      "0% [██████████████████████████] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Train Loss: 0.452 | Val. Loss: 0.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:28\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "N_EPOCHS = 4\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    valid_loss = evaluate(model, val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the dev model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do I need basic finance knowledge for the Finance master?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['question'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 2.729178838478674e-08, 'start': 0, 'end': 1, 'answer': 'I'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "nlp('how are u', 'I am good today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.850306378211826e-05"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(df_dev.loc[1]['question'], df_dev.loc[1]['context'])['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context_file</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1316</td>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>corpus/finance/26.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>corpus/finance/3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1068</td>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>corpus/finance/52.txt</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>Qualifications which are requested to support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969</td>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>corpus/finance/54.txt</td>\n",
       "      <td>76</td>\n",
       "      <td>140</td>\n",
       "      <td>For further information regarding the MSc Fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>529</td>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>corpus/business-analytics/105.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>367</td>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>corpus/business-analytics/73.txt</td>\n",
       "      <td>76</td>\n",
       "      <td>126</td>\n",
       "      <td>For further information regarding the Business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>757</td>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>corpus/finance/28.txt</td>\n",
       "      <td>84</td>\n",
       "      <td>227</td>\n",
       "      <td>While we do welcome students from a wide varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1985</td>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>corpus/finance/3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>644</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1582</td>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>corpus/finance/1.txt</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>Start date: September 2022 Duration: 12 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1073</td>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>corpus/finance/52.txt</td>\n",
       "      <td>378</td>\n",
       "      <td>411</td>\n",
       "      <td>Qualifications which are requested to support ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           question  \\\n",
       "0          1316  Do I need basic finance knowledge for the Fina...   \n",
       "1          1000  For MSc Finance, what is the structure of the ...   \n",
       "2          1068  What is the requirement for GMAR or GRE exam f...   \n",
       "3          1969  For the master program in Finance, who should ...   \n",
       "4           529  What information do I need to provide for my M...   \n",
       "..          ...                                                ...   \n",
       "200         367  Is there a contact email for potential candita...   \n",
       "201         757  Does my bachelor degree has to be highly numer...   \n",
       "202        1985  What is the structure of the program for the m...   \n",
       "203        1582  For the master program in Finance, what is the...   \n",
       "204        1073  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                               answers  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                          context_file  answer_start  answer_end  \\\n",
       "0                corpus/finance/26.txt             0         167   \n",
       "1                 corpus/finance/3.txt             0         644   \n",
       "2                corpus/finance/52.txt           378         411   \n",
       "3                corpus/finance/54.txt            76         140   \n",
       "4    corpus/business-analytics/105.txt             0         232   \n",
       "..                                 ...           ...         ...   \n",
       "200   corpus/business-analytics/73.txt            76         126   \n",
       "201              corpus/finance/28.txt            84         227   \n",
       "202               corpus/finance/3.txt             0         644   \n",
       "203               corpus/finance/1.txt            63          87   \n",
       "204              corpus/finance/52.txt           378         411   \n",
       "\n",
       "                                               context  \n",
       "0    MSc Finance students are expected to have basi...  \n",
       "1    All participants study four core modules in Te...  \n",
       "2    Qualifications which are requested to support ...  \n",
       "3    For further information regarding the MSc Fina...  \n",
       "4    You will need to include a degree transcript i...  \n",
       "..                                                 ...  \n",
       "200  For further information regarding the Business...  \n",
       "201  While we do welcome students from a wide varie...  \n",
       "202  All participants study four core modules in Te...  \n",
       "203  Start date: September 2022 Duration: 12 months...  \n",
       "204  Qualifications which are requested to support ...  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['question', 'answer', 'model_answer', 'confidence_score', 'start_index', 'end_index'])\n",
    "\n",
    "for i in range(df_dev.shape[0]):\n",
    "    output = nlp(df_dev['question'].values[i], df_dev['context'].values[i])\n",
    "    output_df = pd.DataFrame({'question': df_dev['question'].values[i], 'answer': df_dev['answers'].values[i],'model_answer': output['answer'], 'confidence_score': output['score'], 'start_index':output['start'], 'end_index':output['end']}, index=[i])\n",
    "    \n",
    "    result_df = pd.concat([result_df, output_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>basic knowledge in financial mathematics and</td>\n",
       "      <td>6.154369e-07</td>\n",
       "      <td>42</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>providing a robust quantitative underpinning</td>\n",
       "      <td>9.850306e-05</td>\n",
       "      <td>54</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>will only be assessed once an application has ...</td>\n",
       "      <td>8.184416e-04</td>\n",
       "      <td>109</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>applications</td>\n",
       "      <td>1.948936e-02</td>\n",
       "      <td>177</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>Overseas applicants</td>\n",
       "      <td>2.782226e-06</td>\n",
       "      <td>124</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>please see the UCL Postgraduate Admissions</td>\n",
       "      <td>4.927945e-05</td>\n",
       "      <td>170</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>prepare</td>\n",
       "      <td>4.545669e-02</td>\n",
       "      <td>442</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>robust quantitative underpinning</td>\n",
       "      <td>7.472376e-05</td>\n",
       "      <td>66</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>:1 or equivalent in a relevant</td>\n",
       "      <td>1.041819e-02</td>\n",
       "      <td>266</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>will only be assessed once an application has ...</td>\n",
       "      <td>2.917212e-04</td>\n",
       "      <td>109</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Do I need basic finance knowledge for the Fina...   \n",
       "1    For MSc Finance, what is the structure of the ...   \n",
       "2    What is the requirement for GMAR or GRE exam f...   \n",
       "3    For the master program in Finance, who should ...   \n",
       "4    What information do I need to provide for my M...   \n",
       "..                                                 ...   \n",
       "200  Is there a contact email for potential candita...   \n",
       "201  Does my bachelor degree has to be highly numer...   \n",
       "202  What is the structure of the program for the m...   \n",
       "203  For the master program in Finance, what is the...   \n",
       "204  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                                          model_answer  confidence_score  \\\n",
       "0         basic knowledge in financial mathematics and      6.154369e-07   \n",
       "1         providing a robust quantitative underpinning      9.850306e-05   \n",
       "2    will only be assessed once an application has ...      8.184416e-04   \n",
       "3                                         applications      1.948936e-02   \n",
       "4                                  Overseas applicants      2.782226e-06   \n",
       "..                                                 ...               ...   \n",
       "200         please see the UCL Postgraduate Admissions      4.927945e-05   \n",
       "201                                            prepare      4.545669e-02   \n",
       "202                   robust quantitative underpinning      7.472376e-05   \n",
       "203                     :1 or equivalent in a relevant      1.041819e-02   \n",
       "204  will only be assessed once an application has ...      2.917212e-04   \n",
       "\n",
       "    start_index end_index  \n",
       "0            42        86  \n",
       "1            54        98  \n",
       "2           109       200  \n",
       "3           177       189  \n",
       "4           124       143  \n",
       "..          ...       ...  \n",
       "200         170       212  \n",
       "201         442       449  \n",
       "202          66        98  \n",
       "203         266       296  \n",
       "204         109       200  \n",
       "\n",
       "[205 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.to_csv('dev-set-verification/electra-base-squad2.csv')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need basic finance knowledge for the Fina...</td>\n",
       "      <td>MSc Finance students are expected to have basi...</td>\n",
       "      <td>basic knowledge in financial mathematics and</td>\n",
       "      <td>6.154369e-07</td>\n",
       "      <td>42</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For MSc Finance, what is the structure of the ...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>providing a robust quantitative underpinning</td>\n",
       "      <td>9.850306e-05</td>\n",
       "      <td>54</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the requirement for GMAR or GRE exam f...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>will only be assessed once an application has ...</td>\n",
       "      <td>8.184416e-04</td>\n",
       "      <td>109</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the master program in Finance, who should ...</td>\n",
       "      <td>the Programme Administrator via email at: mgmt...</td>\n",
       "      <td>applications</td>\n",
       "      <td>1.948936e-02</td>\n",
       "      <td>177</td>\n",
       "      <td>189</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What information do I need to provide for my M...</td>\n",
       "      <td>You will need to include a degree transcript i...</td>\n",
       "      <td>Overseas applicants</td>\n",
       "      <td>2.782226e-06</td>\n",
       "      <td>124</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Is there a contact email for potential candita...</td>\n",
       "      <td>the Programme Administrator via: mgmt-ba@ucl.a...</td>\n",
       "      <td>please see the UCL Postgraduate Admissions</td>\n",
       "      <td>4.927945e-05</td>\n",
       "      <td>170</td>\n",
       "      <td>212</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Does my bachelor degree has to be highly numer...</td>\n",
       "      <td>we stress to our applicants that this programm...</td>\n",
       "      <td>prepare</td>\n",
       "      <td>4.545669e-02</td>\n",
       "      <td>442</td>\n",
       "      <td>449</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What is the structure of the program for the m...</td>\n",
       "      <td>All participants study four core modules in Te...</td>\n",
       "      <td>robust quantitative underpinning</td>\n",
       "      <td>7.472376e-05</td>\n",
       "      <td>66</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>For the master program in Finance, what is the...</td>\n",
       "      <td>UK/EU/Overseas - £38,000</td>\n",
       "      <td>:1 or equivalent in a relevant</td>\n",
       "      <td>1.041819e-02</td>\n",
       "      <td>266</td>\n",
       "      <td>296</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>For the Finance master, is the requirement for...</td>\n",
       "      <td>We do not require GMAT/GRE scores</td>\n",
       "      <td>will only be assessed once an application has ...</td>\n",
       "      <td>2.917212e-04</td>\n",
       "      <td>109</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Do I need basic finance knowledge for the Fina...   \n",
       "1    For MSc Finance, what is the structure of the ...   \n",
       "2    What is the requirement for GMAR or GRE exam f...   \n",
       "3    For the master program in Finance, who should ...   \n",
       "4    What information do I need to provide for my M...   \n",
       "..                                                 ...   \n",
       "200  Is there a contact email for potential candita...   \n",
       "201  Does my bachelor degree has to be highly numer...   \n",
       "202  What is the structure of the program for the m...   \n",
       "203  For the master program in Finance, what is the...   \n",
       "204  For the Finance master, is the requirement for...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    MSc Finance students are expected to have basi...   \n",
       "1    All participants study four core modules in Te...   \n",
       "2                    We do not require GMAT/GRE scores   \n",
       "3    the Programme Administrator via email at: mgmt...   \n",
       "4    You will need to include a degree transcript i...   \n",
       "..                                                 ...   \n",
       "200  the Programme Administrator via: mgmt-ba@ucl.a...   \n",
       "201  we stress to our applicants that this programm...   \n",
       "202  All participants study four core modules in Te...   \n",
       "203                           UK/EU/Overseas - £38,000   \n",
       "204                  We do not require GMAT/GRE scores   \n",
       "\n",
       "                                          model_answer  confidence_score  \\\n",
       "0         basic knowledge in financial mathematics and      6.154369e-07   \n",
       "1         providing a robust quantitative underpinning      9.850306e-05   \n",
       "2    will only be assessed once an application has ...      8.184416e-04   \n",
       "3                                         applications      1.948936e-02   \n",
       "4                                  Overseas applicants      2.782226e-06   \n",
       "..                                                 ...               ...   \n",
       "200         please see the UCL Postgraduate Admissions      4.927945e-05   \n",
       "201                                            prepare      4.545669e-02   \n",
       "202                   robust quantitative underpinning      7.472376e-05   \n",
       "203                     :1 or equivalent in a relevant      1.041819e-02   \n",
       "204  will only be assessed once an application has ...      2.917212e-04   \n",
       "\n",
       "    start_index end_index comparison  \n",
       "0            42        86      False  \n",
       "1            54        98      False  \n",
       "2           109       200      False  \n",
       "3           177       189      False  \n",
       "4           124       143      False  \n",
       "..          ...       ...        ...  \n",
       "200         170       212      False  \n",
       "201         442       449      False  \n",
       "202          66        98      False  \n",
       "203         266       296      False  \n",
       "204         109       200      False  \n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['comparison'] = np.where(result_df['answer'] == result_df['model_answer'] , 'True', 'False')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    202\n",
       "True       3\n",
       "Name: comparison, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.comparison.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# get tokens from text; just by splitting by spces\n",
    "def get_simple_tokens(text):\n",
    "    tokens = [token.strip() for token in text.split()]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# calculate f1 score for a single prediction-answer pair\n",
    "def get_f1(pred, answer):\n",
    "    pred_tokens = get_simple_tokens(pred)\n",
    "    ans_tokens = get_simple_tokens(answer)\n",
    "    \n",
    "    common_tokens = collections.Counter(pred_tokens) & collections.Counter(ans_tokens)\n",
    "    common_tokens_n = sum(common_tokens.values())\n",
    "    \n",
    "    if common_tokens_n == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = 1.0 * common_tokens_n/len(pred_tokens)\n",
    "    recall = 1.0 * common_tokens_n/len(ans_tokens)\n",
    "    \n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "for i in range(result_df.shape[0]):\n",
    "    f1_scores.append(get_f1(result_df['model_answer'].values[i], result_df['answer'].values[i]))\n",
    "    \n",
    "result_df['f1_score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21725771625057277"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['f1_score'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3b4a3d8190>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3b4a3d85e0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch #')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Binary Cross-Entropy Loss')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3b4a3d87c0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "x = list(range(1, 1+len(train_losses)))\n",
    "\n",
    "plt.plot(x, train_losses, 'b', linewidth=2)\n",
    "plt.plot(x, valid_losses, 'r', linewidth=2)\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.legend(('Training Loss', 'Validation Loss'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
